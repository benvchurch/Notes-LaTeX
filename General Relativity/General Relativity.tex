\documentclass[11pt, a4paper]{article}
\usepackage[total={6in, 9in}]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsthm, amssymb, amsmath}
\usepackage{mathrsfs}

\begin{document}
\author{Benjamin Church}
\title{\Huge A Not So Gentle Introduction to General Relativity}

\newcommand{\R}{\mathbb{R}}
\renewcommand{\d}[1]{\mathrm{d}#1}
\newcommand{\dn}[2]{\mathrm{d}^{#1} #2}
\newcommand{\deriv}[2]{\frac{\d{#1}}{\d{#2}}}
\newcommand{\pderiv}[2]{\frac{\partial{#1}}{\partial{#2}}}
\newcommand{\nderiv}[3]{\frac{\d{^{#1} #2}}{\d{#3}^{#1}}}
\newcommand{\cderiv}[3]{\left(\frac{\partial{#1}}{\partial{#2}}\right)_{#3}}
\newcommand{\cobase}[1]{\vec{e}^{\, #1}}

\theoremstyle{theorem}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem*{problem}{Problem}

\theoremstyle{definition}
\newtheorem{example}{Example}[section]

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\theoremstyle{remark}
\newtheorem{remark}{Remark}[subsection]


\maketitle
\tableofcontents
\newpage

\section{Introduction}

\subsection{The Equivalence Principle}

In 1907, Albert Einstein had the ``happiest thought of his life'',

\begin{quote}
The gravitational field has only a relative existence... Because for an observer freely falling from the roof of a house - at least in his immediate surroundings - there exists no gravitational field.
\end{quote}
The equivalence principle refers to the idea that freely falling in a gravitational field is locally indistinguishable from being out in free space away from any sources of gravitation. Einstein's motivation came from the fact that in Newtonain mechanics the force of gravity of an object is exactly proportional to that objects inertial mass. In Newtonain physics, there seems to be no reason that gravitational mass and inertial mass would have to be exactly equal yet every experiment shows them to be identical. This proportionality has the consequence that all objects accelerate in a gravitational field at the same mass regardless of their mass. In Newtonian physics, this is the reason for weightlessness. It is not that objects in free fall do not experience any forces but rather that since all objects are being accelerated equally, the graviational field does not cause objects to aquire relative velocities which would be measurable. However, this explination is somewhat unsatisfying because it does not explain why such an odd senairo should occur. Einstein realized that the equivalence between free fall and no gravitational field at all is extremely fundamental. The fact that all objects behaved the same way in a gravitational field regardless of their masses suggests that gravity is not a force at all is the usual sense but an effect of geometry. The geometry of space itself is what constitutes the gravitational field and what is responsible for altering the trajectories of moving objects. Gravitational accelerations are not dependent on the mass not due to some strange cancellation but rather because it is the geometrical path through space itself which is being affected. Properties of the object in question are not relevant for all objects are simply following the natural trajectories through a curved spacetime. But what does it mean for space to be curved and how does the curvature affect trajectories of objects through it?

\subsection{What is Curvature?}

Fundamentally, curvature comes down to the idea that distances may be measured differently at different places. Imagine a bug living on a hotplate. Suppose that the bug has a metal ruler which it uses to measure distances and plot courses. However, unbeknownst to the bug, the ruler expands when heated and contracts when cooled. Furthermore, the hotplate is somewhat faulty so that the plate gets hotter as you move twards the center. If the bug wanted to find the shortest path between two points, it would discover that this path curved twards the hotter parts of the plate because fewer ruler lengths would be necessary to traverse through regions in which the ruler is expanded. Furthermore, if the bug measured the distance around the circumfrence of some circle and the radius of the circle, it might not get a ratio of $\pi$ if the inner parts of the circle are at a different temperature than the rest. These are all the hallmarks of a curved space. The standard notion of curvature is to take surface and put it inside some larger ambiant space such that one cannot make a plane tangent to the surface lay flat. This is certianally true but we prefer a more instrinsic notion of curvature, one which can be discussed from the viewpoint of bugs living inside said surface. Curvature will manifest itself in strange geometrical ways such as haing parallel lines diverge or converge, equal segments connected at right angles not meeting up, and circles having a ratio between their curcumference and diameter different from $\pi$. Intrinsically, curvature is about having the measurement of distances be different from place to place. We need such an intrinsic definition because we ourselfs are bugs constrained to live within spacetime. We cannot see the the geometry of our universe as a whole because we are stuck within it but we can measure it.

\section{Tensors}

\subsection{The Principle of General Covariance}

Once we start working with complicated curved spaces, prefered sets of coordinates such as cartesian coordinates will no longer be possible. Most of the definions we will make will be motivated by the principle of general covariance, that the laws of physics should look the same in all reference frams and in all coordinate systems. This principle is extremely powerful and is a guiding principle in cooking up new theories in all branches of modern physics. In essense, the principle of general covariance says that while some coordinate systems may be more convenient for a given problem, all coordinate systems are equally good from the point of view of the fundamental physical laws. The equations should take on the same form no matter what coordinates we use to compute them. There are no privileged frames of reference in physics.   

\subsection{Basis Vectors}

For the time being we will work in a vector space equiped with a metric (or pseudo-metric). It will suffice to study $R^n$ in this section because every real vectorspace is isomorphic to $\R^n$ where $n$ is the dimension of the vectorspace. Although we will use the fact that our space is a vectorspace frequently, we may want to choose coordinates which break the additivity of the space (for example polar coordinates). With the principal of general covariance in mind, we want this discussion to be general to any set of coordinates. 
\par
Given a set of coordinates which we will denote as $(x^1, \cdots, x^n)$ where $n$ is the dimension of the space, we can define a set of basis vectors at each point. We can think of these as vectors in the ambient $\R^n$ euclidean space or as vectors in the tangent space which is a copy of $\R^n$ glued to each point representing the fact that a tangent vector is a local notion. These subleties will not concern us here. We define the covariant basis vectors by,
\[ \vec{e}_i(x^1, \cdots, x^n) = \pderiv{\vec{R}(x^1, \cdots, x^n)}{x^i} \]
which represent the local ``directions'' of each coordinate. The term ``covariant'' will be discussed later. For the coordinate system to be nondegenerate, we require that at every point, the basis vectors from a basis of the ambient space $\R^n$. In general, we define the tangent space at a point to be the span (set of all linear combinations) of the covariant basis vectors.  
\par
Suppose we have two different coordinate systems, or frames, which parametrize our space, $(x^1, \cdots, x^n)$ and $(x'^1, \cdots, x'^n)$. We want to relate the covariant basis in the primed frame to that of the unprimed frame. Using the chain rule,
\[ \vec{e}_i{\, '} = \pderiv{\vec{R}}{x'^i} =  \pderiv{\vec{R}}{x^j} \pderiv{x^j}{x'^i} = \Lambda^j_{i'} \vec{e}_j \] 
where, 
\[\Lambda^j_{i'} = \pderiv{x^j}{x'^i}\]
is the lower transformation symbol and I have introduced Einstein summation conventions where repeated indices are summed over. The transformation symbol is computed by viewing the coordinates on the top as a function of the coordinates on the botto. This is possible because both sets of coordinates can determine any point in the space. The prime on the bottom denotes the fact that the primed coordinates are on the bottom of the derivative. That is the upper transformation symbol is,
\[ \Lambda^{j'}_{i} = \pderiv{x'^j}{x^i} \]
In general, we will call any set of objects that transforms by contracting with the lower transformation symbol covariant. For example,
consider a function $F : \R^n \to \R$. We are going to consider the derivatives of this function with respect to the coordinate systems $(x_1, \cdots, x_n)$ and $(x_1', \cdots, x_n'x)$ where we assume nothing about the relation between these coordinate systems except that each coordinate is a smooth (infinitely differentiable) function of the other. Using the chain rule,
\[ \pderiv{F}{x'_i} = \pderiv{F}{x_j} \pderiv{x_j}{x'_i} \]
This sort of a transformation is know as covariant because the quantity $\pderiv{F}{x_i}$ transforms in the same way as the (covariant) basis.
The opposite notion is contravariant (varying against the basis). For example, consider a curve $\gamma^i(\lambda)$ parametrized by a coordinate $\lambda$. The curve is set of points $(\gamma^1(\lambda), \cdots, \gamma^n(\lambda))$ parametrized by some variable $t$. Consider the tangent vector,
\[ t^i = \deriv{\gamma^i}{\lambda} \]
Technically, what I have defied here is just a bunch of coordinates not a vector. The real tangent vector to the curve is the vector,
\[\vec{t} = \deriv{\vec{R}(\gamma^1(\lambda), \cdots, \gamma^i(\lambda))}{\lambda} = \pderiv{\vec{R}}{x^i} \deriv{\gamma^i}{\lambda} = \vec{e_i} t^i\] 
which lies in the tangent space. Therefore, the object $t^i$ are the components of the true tangent vector. However, we often call $t^i$ a vector in its own right because of how it transforms under the change of coordinates. Consider,
\[ t'^i = \deriv{\gamma'^i}{\lambda} = \deriv{x'^i(\gamma^1(\lambda), \cdots, \gamma^n(\lambda)}{\lambda} = \pderiv{x'^i}{x^j} \deriv{\gamma^j}{\lambda} = \Lambda^{i'}_j t^j \]
Therefore, $t^i$ transforms using the upper transformation symbol so we call $t^i$ contravariant. An object with a single contravariant (upper) index is often called a vector while one with a single covariant (lower) index is called a covector. 

\subsection{The Tensor Property}

\begin{definition}
A type (or rank) $(p,q)$ tensor $T$ is an indexed collection of numbers $T^{i_1 i_2 \cdots i_p}_{j_1 j_2 \cdots j_q}$ which transforms under change of coordinates by the rule known as the tensor property,
\[ T'^{i_1' i_2' \cdots i_p'}_{j_1' j_2' \cdots j_q'} = \Lambda^{i_1'}_{i_1} \Lambda^{i_2'}_{i_2} \cdots \Lambda^{i_p'}_{i_p} \Lambda^{j_1}_{j_1'} \Lambda^{j_2}_{j_2'} \cdots \Lambda^{j_q}_{j_q'} T^{i_1 i_2 \cdots i_p}_{j_1 j_2 \cdots j_q}\]
We call $p$ the contravariant type and $q$ the covariant type. A type $(p, 0)$ tensor is called contravariant and a type $(0, q)$ tensor is called covariant. In particular, a type $(1, 0)$ tensor is called a vector, a type $(0, 1)$ tensor is called a covector, and a type $(0, 0)$ tensor is called a scalar or invariant because it does not transform at all. A tensor of any other type is called ``mixed''.
\end{definition}

Although this definition looks fairly horrible, the idea is very simple. All it says is that $T$ is an indexed set of numbers such that each upper index transforms with an upper transformation symbol and each lower index transforms with a lower transformation symbol. The reason that tensors are important is that if we can form our fundamental physical laws as equations of tensors then they will automatically hold in every reference frame. To see why this is true, suppose that we have the tensor equation, 
\[T^{i_1 \cdots i_p}_{j_1 \cdots j_q} = S^{i_1 \cdots i_p}_{j_1 \cdots j_q}\]
what this means is that the tensors agree componentwise. For this to make sense, both sides of a tensor equation must have the same indices such that we can identify the components that have the same indices. Now suppose we evaluate the tensor $T$ in a new coordinate system,
\[ T'^{i_1' \cdots i_p'}_{j_1' \cdots j_q'} = \Lambda^{i_1'}_{i_1} \cdots \Lambda^{i_p'}_{i_p} \Lambda^{j_1}_{j_1'} \cdots \Lambda^{j_q}_{j_q'} T^{i_1 \cdots, i_p}_{j_1 \cdots j_q} = \Lambda^{i_1'}_{i_1} \cdots \Lambda^{i_p'}_{i_p} \Lambda^{j_1}_{j_1'} \cdots \Lambda^{j_q}_{j_q'} S^{i_1 \cdots i_p}_{j_1 \cdots j_q} = S'^{i_1' \cdots i_p'}_{j_1' \cdots j_q'} \]
so the tensor equation also holds in the new coordinate system. The general fact that if a tensor equation holds in one coordinate system then it must hold in all coordinate systems is, at its core, a consequence of the fact that all tensors, by definition, transform the same way. Tensors provide a perfect language to write physical laws which satisfy the principle of general covariance.  

\subsection{Tensor Products and Contractions}
Given two tensors we can form the tensor product simply by mulipying the components. This gives us a new tensor of a higher type. Explicitly, given a type $(p_1, q_1)$ tensor $T$ and a type $(p_2, q_2)$ tensor $S$ we can form the tensor product $T \otimes S$ or just $TS$ which is a type $(p_1 + p_2, q_1 + q_2)$ tensor with components,
\[ (T \otimes S)^{i_1 \cdots i_{p_1}  i_{p_1 + 1} \cdots i_{p_1 + p_2}}_{j_1 \cdots j_{q_1}  j_{q_1 + 1} \cdots j_{q_1 + q_2}} = T^{i_1 \cdots i_{p_1}}_{j_1 \cdots j_{q_1}} \cdot S^{i_{p_1 + 1} \cdots i_{p_1 + p_2}}_{j_{q_1 + 1} \cdots j_{q_1 + q_2}} \]
This is clearly a $(p_1 + p_2, q_1 + q_2)$ tensor because each index gets an appropriate transformation symbol by virtue of the fact that $T$ and $S$ are tensors. Because it is just multiplication componentwise, the tensor product is symmetric if both the indices and the tensors are swapped.  
\par
Now we know how to make tensors of higher type but we can also make tensors with lowered type by index contraction. To contract an upper and lower index, we take the trace over those indices. For example, given the type $(2,1)$ tensor, $T^{ij}_{k}$ we can form a type $(1,0)$ tensor $S^i$ by taking,
\[S^i = T^{ij}_{j} = \sum_{j = 1}^n T^{ij}_j \]
remembering the Einstien summation convention. I need to show that this construction satisfies the tensor property. The Kronecker delta $\delta^i_j$ is defined to be the components of the identity matrix,
\[ \delta^i_j = 
\begin{cases}
1 & i = j\\
0 & i \neq j
\end{cases}\]
By the definition of partial derivatives,
\[ \Lambda^{i'}_k \Lambda^{k}_{j'} = \pderiv{x'^i}{x^k} \pderiv{x^k}{x'^i} = \pderiv{x'^i}{x'^j} = \delta^i_j \]
and similarly,
\[ \Lambda^{i}_{k'} \Lambda^{k'}_{j}=  \pderiv{x^i}{x'^k} \pderiv{x'^k}{x^i}  = \pderiv{x^i}{x^j} = \delta^i_j \]
Therefore the upper and lower tranformation symbols are inverses. Now, consider the transformation of $S$,
\[S'^{i'} = T'^{i'j'}_{j'} = \Lambda^{i'}_{i} \Lambda^{j'}_{j_1} \Lambda^{j_2}_{j'} T^{ij_1}_{j_2} = \Lambda^{i'}_{i} \delta^{j_1}_{j_2} T^{ij_1}_{j_2} = \Lambda^{i'}_{i} T^{ij_1}_{j_1} = \Lambda^{i'}_{i} S^{i} \]
Therefore, $S^1$ is a type $(1, 0)$ tensor. This construction, contracting over an upper and a lower index, works in general and transforms a type $(p, q)$ tensor into a type $(p-1, q-1)$ tensor. 
\par
A very important special case of contraction is forming invariants form tensors. For example, given a type $(1, 1)$ tensor $T$ we can contract to form a type $(0, 0)$ tensor which is by definition an invariant. Explicitly, let $S = T^{i}_{i}$ then $S$ transforms as,
\[ S' = T'^{i'}_{i'} = \Lambda^{i'}_{j} \Lambda_{i}^{k} T^{j}_{k} = \delta^{k}_{j} T^{j}_{k} = T^{j}_{j} = S\]
Thus, $S$ is an invariant, it has the same value in all coordinate systems. Invariants are extremely important in physics because they have the wonderful property that you only ever need to compute them once any you can choose whatever coordinate system is most convenient in which to do this computation. There will be many applications of forming invariants out of tensors. One very important invariant is the inner prodcut of a type $(1, 0)$ tensor $A$ and a type $(0, 1)$ tensor $B$ given by $A \cdot B = A^i B_i$ which is the contraction of the tensor product. Of course, we can also define it the other way for a type $(0, 1)$ tensor $A$ and a type $(1, 0)$ tensor $B$ in which case $A \cdot B = A_i B^i$ again the contraction of the tensor product. Once we have the metric tensor to deal with, we will be able to take the inner product of two vectors or two covectors or really any two tensors whatsoever. 

\subsection{The Intrinsic Notion of a Tensor}
\begin{remark}
I recommend skipping this section unless you have a strong background in (multi)linear algebra. The concepts expressed here are very interesting but are not necessary to the remainder of the course.
\end{remark}

We have already seen one example of an invariant inner product, the tangent vector as an element of the tangent space. Since we saw that $\vec{e}_i$ forms a (vector-valued) rank-$1$ covariant tensor or covector and $t^i$ a (real number valued) rank-$1$ contravariant tensor or vector. Therefore, we can take the inner product to form an invariant,
\[ \vec{t} = \vec{e}_i \, t^i \] 
which is the geometric tangent vector in the tangent space we defined earlier. This is an invariant geometric vector which means it is a geometric object which is invariant under transformations of coordinates used to define it. This geometric vector lives in the ambient vector space so it is a fundamentally different beast than the (not invariant since it is a tensor of non-trivial type) vector $t^i$ of components.In fact, all tensors have some sort of coordinate-independent abstract geometric realization. This geometric object $T$ is represented by the coordinate dependent indexed set of numbers $T^{i_1 \cdots i_p}_{j_1 \cdots j_q}$. The fact that $T$ is an invariant object and has a coordinate independent meaning is captured by the specific transformation law satisfied by its component representation. 
\par
For the mathematically inclined, we can give a puely geometric definition of tensors. However, because these objects are abstract, the only way to do actual computations with them is using a coordinate representation. That said, the invariant coordinate independent notion is important conceptually for thinking as the entire tensor as a geometric ``thing''. Given a manifold $M$\footnote{We will come back to what this means in the next chapter. For now, think of it simply as some space.}, we can define the tangent space at a point $p$ denoted by $T_p M$ as the span of the covariant basis. This is a finite-dimensional vectorspace. Then, the space of all type $(k, \ell)$ tensors at the point $p$ is given by,
\[ (T^k_\ell)_p = (T_p M)^{\otimes k} \otimes (T^*_p M)^{\otimes \ell}\]
where $T_p^* M = (T_p M)^*$ is the cotangent space which is defined to be the dual space of the tangent space. However, this is the space of all tensors at a given point. What we really care about is the bundle of all $(k,l)$-tensors everywhere on our space,
\[T^k_l = \coprod_{p \in M} (T_p M)^{\otimes k} \otimes (T^*_p M)^{\otimes \ell}\]
An abstract tensor can be defined by its components. Let $e_i$ be the covariant basis at a point $p$ and let $e^i$ be the dual (contravariant) basis also at $p$. Then given a coordinate representation of a $(k, \ell)$ tensor we can define a type $(k, \ell)$ tensor at the point $p$ by,
\[ T = T^{i_1 \cdots i_k}_{j_1 \cdots j_\ell} \cdot e_{i_1} \otimes \cdots \otimes e_{i_{k}} \otimes e^{j_1} \otimes \cdots \otimes e^{j_{\ell}} \in (T^{k}_{\ell})_p\]
using Einstien summation convention. Because this is a total contraction of tensors, the object $T$ is invariant. Up until now, we have only talked about tensors defined at a given point. However, what we really care about is tensor fields which are the association of a tensor to each point in space. This is where the bundle of all tensors will come in handy. We define a type $(k, \ell)$ tensor field $\sigma$ as a section of the bundle  of type $(k, \ell)$ tensors. That is, a map $\sigma : M  \to T^k_{\ell}$ such that each point is sent to a tensor at that point, $\sigma(p) \in (T^k_{\ell})$ for each $p \in M$.

\subsection{The Metric Tensor}

Because we have a dot product in our ambient space (on geometric objects) we can define the metric (rank $2$ covariant) tensor given by dot products of the covariant basis,
\[ g_{ij} = \vec{e}_i \cdot \vec{e}_j \]
Because the dot product is commutative, the metric tensor is symmetric, $g_{ij} = g_{ji}$.
The metric tensor is the object we use to measure  the lengths of vectors and the distances between points. To see this, consider a small geometric displacement vector,
\[
\d{\vec{R}} = \pderiv{\vec{R}}{x^i} \d{x^i} = \vec{e}_i \d{x^i}
\]
The squared length of this vector is given by,
\[ \d{\vec{R}}^2 = (\vec{e}_i \d{x^i}) \cdot (\vec{e}_j \d{x^j}) = \vec{e}_i \cdot \vec{e}_j \d{x}^i \d{x}^j = g_{ij} \d{x^i} \d{x^j} \]
Therefore, the metric tells us how to calculate the length of small displacements given their coordinates. Now we can define the contravariant metric tensor which is a type $(2,0)$ tensor, $g^{ij}$ defined to be the inverse of $g_{ij}$. That is,
\[ g^{ij} g_{j k} = \delta^{j}_{k} \quad \text{and} \quad g_{ij} g^{jk} = \delta^{i}_{k}\]
We can use the covariant and contravariant versions of the metric to perform ``index juggling'' which consisting of moving indices up and down. Given a vector $A^i$ we can construct a covector $A_i = g_{ij} A^j$. Similarly, given a covector $B_i$ we can construct a vector $B^i = g^{ij} B_j$. Similarly, we can raise and lower any index of a mixed tensor using $g_{ij}$ and $g^{ij}$. Because these tensors are inverses, rasing and lowering indices are inverse operations. 
\par
Using this definition, we can define an invariant from any vector or covector. Given a vector $A^i$ define the invariant,
\[A \cdot A = A^i A_i = g_{ij} A^{i} A^{j}\] Likewise, given a covector $B_i$ define,
\[ B \cdot B = B_i B^i = g^{ij} B_i B_j \] 
Furthermore, define the contravariant basis,
\[ \vec{e}^{\, i} = g^{ij} \vec{e}_j \]
which transforms as a contravariant tensor of geometric vectors.

\begin{theorem}
Properties of the Metric,
\begin{enumerate}
\item Symmetric, $g_{ij} = g_{ji}$

\item The contravariant basis contracts to form the contravariant metric, 
\[\cobase{i} \cdot \cobase{j} = g^{ik} \vec{e}_k \cdot g^{j \ell} \vec{e}_{\ell} = g^{ik} g^{j \ell} g_{k \ell} = g^{ik} \delta^j_k  = g^{ij}\]

\item The covariant and contravariant bases are orthonormal or dual,
\[ \vec{e}_i \cdot \cobase{j} = g^{jk} \vec{e}_i \cdot \vec{e}_k = g^{jk} g_{ik} = \delta^j_i \]
and similarly,
\[ \cobase{i} \cdot \vec{e}_j = g^{ik} \vec{e}_k \cdot \vec{e}_j = g^{ik} g_{kj} = \delta^i_j \]
\end{enumerate}
\end{theorem}

\subsection{Determinants}

In general realtivity, we care almost exclusively about four-dimensional spaces. Therefore, we will discuss the theory of determinants explicitly in the case $n = 4$ for rank two tensors. However, these results are all easily generalized to arbitrary dimensions.
We first define the fully skew symmetric symbol, $S_{ijkl}$ by the properties,
\begin{enumerate}
\item $S_{0000} = 1$
\item Swapping any two indices changes sign $S_{ijkl} = - S_{jikl} = S_{jilk}$ etc.
\item If any index is repeated then the symbol is zero $S_{iikl} = S_{ijkk} = 0$.
\end{enumerate}

\begin{definition}
For the dimension $n = 4$ we can define the deterinant $A$ of a type $(0, 2)$ tensor $a_{ij}$ by,
\[ S_{ijkl} a_{ai} a_{bj} a_{ck} a_{dl} = A S_{abcd}\]
where repeated indices are summed. 
\end{definition}
This is a valid definition because the left hand side is fully skew symmetric since,
by,
\[ S_{ijkl} a_{bi} a_{aj} a_{ck} a_{dl} = A S_{abcd} = - S_{jikl} a_{bi} a_{aj} a_{ck} a_{dl} = -  S_{jikl} a_{aj} a_{bi}  a_{ck} a_{dl} \]
which is equal by renaming. One can explicitly check that,
\[ S_{ijkl} S_{ijkl} = 4! \]
Therefore, the determinant of $a$ with lower indices is given by the formula,
\[ \det{a_{\cdot \cdot}} = A = \frac{1}{4!} S_{abcd} S_{ijkl} a_{bi} a_{aj} a_{ck} a_{dl}\]

\begin{theorem}
$\det{(a_{\cdot i} b^{i \cdot})} = \det{(a_{\cdot \cdot})} \cdot \det{(b^{\cdot \cdot})}$
\end{theorem}

\begin{proof}
(DO THIS PROOF)
\end{proof}

Using the same idea as the definition of the determinaint, we can define a new tensor of cofactors which will give us a tensor similar to the inverse. 

\begin{definition}
The cofactor tensor of $a_{\cdot \cdot}$ is a type $(2,0)$ tensor $A^{ia} = \frac{1}{3!} S_{abcd} S_{ijkl} a_{bj} a_{ck} a_{dl}$. 
\end{definition}
The cofactor tensor is almost the inverse. It differs only by a numberical factor which happens to be exactly the determinant. Explicitly,
\begin{theorem}
$A^{im} a_{mj} = A \delta^i_j$ so if the inverse exists, $A^{ij} = A (a^{-1})^{ij}$
\end{theorem}

\begin{proof}
$A^{im} a_{mj} = \frac{1}{3!} S_{mbcd} S_{iklr} a_{mj} a_{bk} a_{cl} a_{dr} = \frac{1}{3!} S_{jklr} S_{iklr} = \delta^i_j$
\end{proof}

\begin{theorem}
\[\pderiv{A}{a_{ij}} = A^{ji} = A(a^{-1})^{ji}\]
\end{theorem}

\begin{proof}
\[\pderiv{}{a_{ij}} \left[ \frac{1}{4!} S_{abcd} S_{rskl} a_{ar} a_{bs} a_{ck} a_{dl} \right] = \frac{4}{4!} \delta^a_i \delta^r_j S_{abcd} S_{rskl} a_{bs} a_{ck} a_{dl} = \frac{1}{3!} S_{ibcd} S_{jskl} a_{bs} a_{ck} a_{dl} = A^{ji} \]
\end{proof}


\subsection{The General Transformation Symbol}

\begin{definition}
$\mathfrak{T}$ is a type $(p,q)$ relative tensor of weight $W$ if,
\[ \mathfrak{T'}^{i'_1 \cdots i'_q}_{j'_1 \cdots j'_q} = \Lambda^W \Lambda^{i'_1}_{i_1} \cdots \Lambda^{i'_p}_{i_p} \cdots \Lambda^{j_1}_{j'_1} \cdots \Lambda^{j_q}_{j'_q} \mathfrak{T}^{i_1 \cdots i_q}_{j_1 \cdots j_q}\]
where $\Lambda^W = \det{(\Lambda^{'}_{\cdot})}^W$. Equivalently,
\[ \mathfrak{T'}^{i'_1 \cdots i'_q}_{j'_1 \cdots j'_q} \Lambda^{i_1}_{i'_1} \cdots , \Lambda^{i_p}_{i'_p} \cdots \Lambda^{j'_1}_{j_1} \cdots \Lambda^{j'_q}_{j_q} = \Lambda^W \mathfrak{T}^{i_1 \cdots i_p}_{j_1 \cdots j_q}\]
\end{definition}
If we try to transform the transformation symbol, we find that it is a relative tensor of weight $1$ because,
\[ S'_{ijkl} \Lambda^{i}_a \Lambda^j_b \Lambda^k_c \Lambda^l_d = S_{ijkl} \Lambda^{i}_a \Lambda^j_b \Lambda^k_c \Lambda^l_d = \Lambda S_{abcd} \] 
Let $g = \det{(g_{\cdot \cdot})}$. Using the fact that, $g^{ik} g_{kj} = \delta^i_j$ then,
\[ \det{(g^{\cdot \cdot})} \cdot \det{(g_{\cdot \cdot})} = 1 \]
Therefore, $\det{(g^{\cdot \cdot})} = g^{-1}$.   



\subsection{The Levi-Civita Tensor}

\section{The Basic Theory of Manifolds}

\subsection{Definition}

\subsubsection{Euclidean and Minkowski Spaces}

\subsection{From Space to Space-Time}

\subsection{The Covariant Derivative}

To discuss curvature, we will need to take the derivatives of tensors. However, here we reach an issue. In general, the derivative of a tensor will not be a tensor. To see the difficulty, consider,
\[ \partial'_{i'} A'^{j'} = \Lambda_{i'}^i \partial_i (\Lambda^j_{j'} A^j) = \Lambda_{i'}^i \Lambda^j_{j'} \partial_i  A^j +  \Lambda_{i'}^i A^j \partial_i \Lambda^j_{j'} \]
which is not zero because the transformation symbol may vary from place to place. This extra term means that the derivative of $A$ is not a tensor. We will need to fix this problem if we hope to apply our theory to differential equations of tensors. 
\par
Geometrically, the issue is one of connection. The manifold has a tangent space attached at each point but we don't have an \textit{a priori} way to connect a tangent vector at one point to a tangent vector at another point. Since the coordinates may be quite wonky, there will not be a natural way to extend the tangent spaces to make a single vectorspace in which all vectors can be compared as they can be for cartesian coordinates. Explicitly, the issue is that as one moves about the manifold, the basis vectors change which means that the geometrical meaning of the components of a vector changes from place to place. Without a way to compare the components of a vector at neighborhing places, we cannot define a derivative that makes sense. It turns our we can solve both these problems simultaneously by making use of the ambient euclidean space. Since each tangent space is embedded in the ambient space, we do have a natural way to compare vectors. Therefore, we should use the geometric invariant we cooked up before. I claim that the quantity,
\[ \nabla_i A^k =  \cobase{k} \cdot \partial_i (\vec{e}_j A^j) \]
is a type $(1, 1)$ tensor because $\vec{e}_j A^j$ is an invariant so we have no issues with differentiating a transformation symbol under changes of coordinates. This combination is known as the covariant derivative because it is a derivative which is a covariant tensor. However, it is not immediately clear that this definition reduces to the standard derivative in ``nice'' coordinates. We can write the covariant derivative in a more explicit form,
\[ \nabla_i A^k =  \cobase{k} \cdot \partial_i (\vec{e}_j A^j) = \cobase{k} \cdot \vec{e}_j \partial_i A^j + A^j \left( \cobase{k} \cdot \partial_i \vec{e}_j \right) = \partial_i A^k + A^j \Gamma^k_{ij} \]
where the Christoffel symbols $\Gamma^k_{ij}$ appear naturally.

\begin{definition}
The Christoffel symbol is defined the indexed set of coeficients,
\[ \Gamma^k_{ij} = \cobase{k} \cdot \pderiv{\vec{e}_j}{x^i} \]
\end{definition}  
Note that $\Gamma^k_{ij}$ is called the Christoffel \textit{symbol} \textbf{not} the Christoffel \textit{tensor} because it does not transform as a tensor due to the derivative of an non-invariant object. However, the non-covariance of the Christoffel symbol exactly cancels the failure of $\partial_i A^k$ to be a tensor such that the combination in the covariant derivative satisfies the tensor property. The Christoffel symbol has many nice properties which we will need to expliot over and over again.

\begin{lemma}
Properties of the Christoffel Symbol,
\begin{enumerate}
\item $\Gamma^k_{ij} = \Gamma^k_{ji}$

\item $\vec{e}_k \cdot \pderiv{\cobase{j}}{x^i} = - \Gamma^{j}_{ik}$

\end{enumerate}
\end{lemma} 

\begin{proof}
(DO PROOF)
\end{proof}

We can similarly define a covariant derivative for covectors by considering the invariant geometric covector which has a tensorial derivative,
\[ \nabla_i A_k =  \vec{e}_k \cdot \partial_i (\cobase{j} A_j) = \vec{e}_{k} \cdot \cobase{j} \partial_i A_j + A_j \left( \vec{e}_{k} \cdot \partial_i \cobase{j} \right) = \partial_i A_k - A_j \Gamma^j_{ik} \]
This suggests the following definition,
\begin{definition}
The covariant derivative of a type $(p,q)$ tensor $T$ is the type $(p, q+1)$ tensor,
\[ \nabla_{i} T^{i_1 \cdots i_p}_{j_1 \cdots j_q} = \partial_i T^{i_1 \cdots i_p}_{j_1 \cdots  j_q} + T^{k \cdots i_p}_{j_1 \cdots j_q} \Gamma^{i_1}_{k i} + \cdots + T^{i_1 \cdots k}_{j_1 \cdots j_q} \Gamma^{i_p}_{k i} - T^{i_1 \cdots i_p}_{k \cdots  j_q} \Gamma^{k}_{j_1 i} + \cdots - T^{i_1 \cdots i_p}_{j_1 \cdots k} \Gamma^{k}_{j_q i} \]
\end{definition}
Using the invariant geometric notion of the tensor which has a coordinat independent derivative because it is an invariant, we can prove that the above definition always produces a tensor. Alternatively, this can be checked explicitly by evaluating it in  a new coordinate system. I absolutly do not recommend doing this because it is beyond horrible. 

\begin{lemma}[The Product Rule]
For any two tensors $T$ and $S$, the covariant derivative satisfies the product rule,
\[\nabla (T \otimes S) = (\nabla  T) \otimes S + T \otimes (\nabla S)\]
\end{lemma}

\begin{proof}
This follows simply by the product rule for normal derivatives and factoring. We will show this explicitly for the special case of type $(0, 1)$ tensors,
\begin{align*}
\nabla_k (A_i B_j) & = \partial_k (A_i B_j) - A_\ell B_j \Gamma^\ell_{i k} - A_i B_{\ell} \Gamma^\ell_{k j}
\\
& = B_j \partial_k A_i + A_i \partial_k B_j - A_\ell B_j \Gamma^\ell_{i k} - A_i B_{\ell} \Gamma^\ell_{k j}  
\\
& = B_j \left( \partial_k A_i - A_\ell \Gamma^\ell_{i k} \right) + A_i \left( \partial_k B_j - B_{\ell} \Gamma^\ell_{k j}  \right)
\\
& = (\nabla_k A_i) B_j + A_i (\nabla_k B_j)
\end{align*}
\end{proof}

\subsection{Covariant Derivative of the Metric}
The covariant derivative of the metric can be explicitly computed,
\begin{align*}
\nabla_kg_{ij} &= \pderiv{(\vec{e}_i\cdot \vec{e}_j)}{x^k} - g_{mj} \Gamma^m_{ik} - g_{im} \Gamma^m_{jk}
\\
& = \pderiv{\vec{e}_i}{x^k}\cdot \vec{e}_j  + \vec{e}_i\cdot \pderiv{\vec{e}_j}{x^k} - g_{mj} \cobase{m} \cdot \pderiv{\vec{e}_i}{x^k} - g_{im} \cobase{m} \cdot \pderiv{\vec{e}_j}{x^k} 
\\
& = \pderiv{\vec{e}_i}{x^k}\cdot \vec{e}_j  + \vec{e}_i\cdot \pderiv{\vec{e}_j}{x^k} - \vec{e}_j \cdot \pderiv{\vec{e}_i}{x^k} - \vec{e}_i \cdot \pderiv{\vec{e}_j}{x^k} = 0 
\end{align*}
Therefore, the covariant derivative of the metric is always zero. This implies that if we can find a coordinate system in which the Christoffel symbols vanish at a point, then the coordinate derivatives of the metric also vanish. Such a reference frame is known as a locally intertial frame in general relativity and will be very important for simplifying calculations. 
This important property makes our definition of the covariant derivative well-defined under index juggling. That is, the covariant derivative commute with index juggling. Consider,
\[\nabla_k A_i = \nabla_kg_{ij}A^j = A^j\nabla_kg_{ij}+g_{ij}\nabla_kA^j = g_{ij}\left[\pderiv{A^j}{x^k} + A^m\Gamma^j_{mk}\right] \]
Furthermore, 
\begin{align*}
g_{ij}\left[\pderiv{A^j}{x^k} + A^m\Gamma^j_{mk}\right] & = \pderiv{A_i}{x_k}-A^j\pderiv{g_{ij}}{x^k} + g_{ij}A^m\Gamma^j_{mk}
\\
& =  \pderiv{A_i}{x^k} - A^j_{mj}\Gamma^m_{lk} - A^jg_{im}\Gamma^m_{jk} + A^mg_{ij}\Gamma^j_{mk}
\\
& = \pderiv{A_i}{x^k} - A_m\Gamma^m_{ik}
\end{align*}
which is consistent with our definition that,
 \[ \nabla_kA_i = \pderiv{A_i}{x^k} - A_m\Gamma^m_{ik}\]
Index jugling in the other direction also works because $\nabla_kg^{ij} = 0$. Therefore,  we can raise and lower indices inside a covariant derivative without issue since rasing with the metric inside the derivative is the same as rasing with the metric outside. 
\par
There is one further important set of quantities we would like to know the covariant derivtive of, the basis vectors. Consider,
\[ \nabla_i \vec{e}_j = \pderiv{\vec{e}_j}{x^i} - \vec{e}_k \Gamma^k_{ij} = \left( 1 - \vec{e}_k \otimes \cobase{k} \right) \cdot \pderiv{\vec{e}_j}{x^i} \]
The operator  $\vec{e}_k \otimes \cobase{k}$ is a map from the ambient space of geometric vectors to the tangent space acting by the dot product with a vector,
\[ (\vec{e}_k \otimes \cobase{k}) \cdot \vec{v} = \vec{e}_k \: (\cobase{k} \cdot \vec{v}) \]
Because $\vec{e}_k$ is a basis of the tangent space and $\vec{e}_i \cdot \cobase{j} = \delta_i^j$ we know that if $\vec{v} = v^i \vec{e}_i$ is in the tangent space then,
\[ (\vec{e}_k \otimes \cobase{k}) \cdot \vec{v} = (\vec{e}_k \otimes \cobase{k}) \cdot v^i \vec{e}_i = \vec{e}_k v^i \: (\cobase{k} \cdot \vec{e}_i) = \vec{e}_k v^i \delta^k_i = \vec{e}_k v^k = \vec{v}  \]
Thus, $\vec{e}_k \otimes \cobase{k}$ is the projection operator from the ambiant space onto the tangent space since it taken any vector into the ambiant space and preserves any vector already in the tangent space. Therefore, 
\[ 1 - \vec{e}_k \otimes \cobase{k} \]
is the orthogonal projector to the tangent space. This operator takes any vector and subtracts out the component in the tangent space leaving only the component perpendicular to the tangent space. Therefore, the covariant derivative of the basis,
\[ \nabla_i \vec{e}_j = \pderiv{\vec{e}_j}{x^i} - \vec{e}_k \Gamma^k_{ij} = \left( 1 - \vec{e}_k \otimes \cobase{k} \right) \cdot \pderiv{\vec{e}_j}{x^i} \]
gives the component of the change in $\vec{e}_j$ in the direction $x^i$ which is pointing out of the tangent space. If the tangent space has the same dimension as the ambiant space we are embedded in then the basis $\vec{e}_i$ spans the entire space so the covariant derivative of the basis vectors is identically zero. Furthermore, 
\[ \nabla_i \cobase{j} = \pderiv{\cobase{j}}{x^i} + \cobase{k} \Gamma^j_{ik} = \pderiv{\cobase{j}}{x^i} - \cobase{k}  \cdot \left( \vec{e}_k \cdot \pderiv{\cobase{j}}{x^i} \right) = \left(1 - \cobase{k} \otimes \vec{e}_k \right) \cdot \pderiv{\cobase{j}}{x^i} \]
which has the exact same properties but is a map from the ambiant space of covectors to the cotangent space. Similarly, if the dimension of the cotangent space (which is equal to the dimension of the tangent space because they are finite dimensional) is equal to the dimension of the ambiant space then the covariant derivative of the contravariant basis is also zero,
\[ \nabla_i \cobase{j} = 0 \]

\subsection{Calculating Christoffel symbols}
From the above derivation we find, 
\begin{enumerate}
    \item $\nabla_kg_{ij} = 0 \implies \pderiv{g_{ij}}{x^k} = g_{mj}\Gamma^m_{ik} + g_{im}\Gamma^m_{jk}$
    \item $\nabla_ig_{kj} = 0 \implies \pderiv{g_{kj}}{x^k} = g_{mj}\Gamma^m_{ki} + g_{km}\Gamma^m_{ji}$
    \item $\nabla_jg_{ki} = 0 \implies \pderiv{g_{ki}}{x^j} = g_{mi}\Gamma^m_{kj} + g_{km}\Gamma^m_{ij}$
\end{enumerate}
Then, noting that $\Gamma^m_{ij} = \Gamma^m_{ij}$ taking  $(2)+(3)-(1)$ we get,
\[\pderiv{g_{kj}}{x^i} + \pderiv{g_{ki}}{x^j} - \pderiv{g_{ij}}{x^k} = 2g_{km}\Gamma^m_{ij}\]
We multiply both sides of this equation by $\frac{1}{2}g^{rk}$ and thus, 
\[\Gamma^r_{ij}  = \frac{1}{2}g^{rk}\left(\pderiv{g_{kj}}{x^i} + \pderiv{g_{ki}}{x^j} - \pderiv{g_{ij}}{x^k}\right)\]
This can be used to caluclate the Christoffel symbols explicitly from the metric.

\subsection{The Covariant Derivative Along a Curve}

Given a curve $\vec{\gamma}(\lambda) = \vec{R}(\gamma_1(\lambda), \cdots, \gamma_n(\lambda))$ parametrized by $\lambda$, we have the tangent vector: 
\[\vec{t} = \deriv{\vec{\gamma}}{\lambda} = \deriv{x^k}{\lambda} \pderiv{\vec{R}}{x^k} = t^k\vec{e}_k\]
If we have a vector $\vec{v} = v^i\vec{e}_i$ in the tangent space defined at each point on the curve,
\begin{align*}
\deriv{\vec{v}}{\lambda} = \deriv{v^k}{\lambda}\vec{e}_i + v^i \pderiv{\vec{e}_i}{x^k} \deriv{x^k}{\lambda} = \deriv{v^i}{\lambda} \vec{e}_i + v^i\vec{e}_m\Gamma^m_{ik}t^k = \left(\deriv{v^i}{\lambda} + v^m\Gamma^i_{mk}t^k \right) \vec{e}_i
\end{align*}
where we changed the indices of the second term.  We now define, the derivative along a curve by, 
\[D_\lambda v^i = \nabla_{\gamma(\lambda)} v^i = \deriv{v^i}{\lambda} + v^m\Gamma^i_{mk}t^k\]
which produces tensors.  Similarly, we may write this in terms of lowered indices as, 
\[\nabla_{\gamma(\lambda)} v_i = \deriv{v_i}{\lambda} - v_m\Gamma^m_{ik}t^k\]
This derivative along a curve is related to the covariant derivative by, 
\[\nabla_{\gamma(\lambda)}v^i = t^k \nabla_k v^i = \deriv{x^k}{\lambda} \pderiv{v^i}{x^k} + v^m\Gamma^i_{mk}t^k = \deriv{v^i}{\lambda} + v^m\Gamma^i_{mk}t^k\]
This allows us to find the acceleration in any coordinates that transforms.  So if $\lambda = $ time, and $t^k = v^k$, the velocity, then we get the acceleration: 
\[ D_t v^k = \nderiv{2}{x^k}{t} + v^m\Gamma^k_{mn} v^n = a^k\]

\begin{remark}[Notation]
In the next section I will begin to use the Greek convention for spacetime indices. The only reason is to get farmiliar with the convention. I will use Greek indices for any index for a spacetime coordinate (of a Mikowski-like manifold) in the range $0, 1, 2, 3$ for $3 + 1$ dimensions. I will use Latin indices for spatial coordinates (of a Euclidean-like manifold) in the range $1, 2, 3$ for $3$ dimensions. If a tensor in spacetime appears with Latin indices it means the index runs only over spatial coordinates and not the time component(s). The results of the following section are generally true for any space or space-time whether it be Euclidean or Minkowski. As such, I will illustrate with an example in 3-dimensional Euclidean space. 
\par
In the comming sections there will be many derivatives which will quickly get very tiresome to write out in full. Here I introduce the following shorthand notation,
\[ \partial_\mu = \pderiv{}{x^\mu} \]
for a derivative with respect to the coordinates. Furthermore, given quantities which depend on a parameter $\lambda$, I introduce the shorthand notation,
\[ \partial_\lambda = \deriv{}{\lambda}\]
for the total derivative with respect to $\lambda$. While these notations are very standard, they have the unfortunate ambiguity that $\partial_\lambda$ looks like a coordinate derivative with respect to the spacetime index $\lambda$. Unfortunately, we have run out of letters for parameters since any Greek letter can represent a spacetime index and any Latin letter can represent a spatial index. To ameliorate this faliure of notation, I will never use $\lambda$ as an index, only as a parameter. 
\end{remark}

\subsection{The Voss-Weyl Formula}

We need to futher investigate the properties of determinants under differentiation.
\begin{lemma}
\[\pderiv{\sqrt{g}}{g_{\mu \nu}} = \tfrac{1}{2} \sqrt{g} \, g^{\mu \nu} \quad \text{and} \quad \pderiv{\sqrt{g}}{g^{\mu \nu}} = -\tfrac{1}{2} \sqrt{g} \, g_{\mu \nu} \] 
\end{lemma}
\begin{proof}
\[\pderiv{\sqrt{g}}{g_{\mu \nu}} = \frac{1}{2 \sqrt{g}} \pderiv{g}{g_{\mu \nu}} = \frac{1}{2 \sqrt{g}} g \, g^{\nu \mu} = \tfrac{1}{2} \sqrt{g} \, g^{\mu \nu}\]
Similarly,
(FINISH PROOF)
\end{proof}

\begin{lemma}
\[ \pderiv{\sqrt{g}}{x^{\mu}} = \sqrt{g} \, \Gamma^{\nu}_{\nu \mu}\]
\end{lemma}

\begin{proof}
\[ \pderiv{\sqrt{g}}{x^\mu} = \frac{1}{2 \sqrt{g}} \pderiv{g}{g_{\alpha \beta}} \pderiv{g_{\alpha \beta}}{x^{\mu}}\]
However, we know that,
\[ \pderiv{g}{g_{\alpha \beta}} = g g^{\alpha \beta} \quad \text{and} \quad \pderiv{g_{\alpha \beta}}{x^\mu} = \vec{e}_{\alpha} \cdot \pderiv{\vec{e}_{\beta}}{x^\mu} + \pderiv{\vec{e}_{\alpha}}{x^{\mu}} \cdot \vec{e}_{\beta}  \]
Therefore,
\begin{align*}
 \pderiv{\sqrt{g}}{x^\mu} & = \tfrac{1}{2} \sqrt{g} \, g^{\alpha \beta} \left[ \vec{e}_{\alpha} \cdot \pderiv{\vec{e}_{\beta}}{x^\mu} + \pderiv{\vec{e}_{\alpha}}{x^{\mu}} \cdot \vec{e}_{\beta} \right] = \tfrac{1}{2} \sqrt{g} \,  \left[  \cobase{\beta} \cdot \pderiv{\vec{e}_{\beta}}{x^\mu} + \cobase{\alpha} \cdot \pderiv{\vec{e}_{\alpha}}{x^{\mu}}  \right] 
\\
 & = \tfrac{1}{2} \sqrt{g} \left[ \Gamma^\beta_{\beta \mu} + \Gamma^{\alpha}_{\alpha \mu} \right] = \sqrt{g} \, \Gamma^{\alpha}_{\alpha \mu}
\end{align*}
\end{proof}

\begin{theorem}[Voss-Weyl]
\[ \nabla_\mu V^\mu = \frac{1}{\sqrt{g}} \partial_\mu \left( \sqrt{g} \, V^\mu \right) \]
\end{theorem}

\begin{theorem}
\begin{align*}
\frac{1}{\sqrt{g}} \partial_\mu \left( \sqrt{g} \, V^\mu \right) & = \partial_\mu V^\mu + \frac{1}{\sqrt{g}} V^\mu \partial_\mu (\sqrt{g})  = \partial_\mu V^\mu + V^\mu \Gamma^{\nu}_{\nu \mu} 
\\
& = \partial_\mu V^\mu + V^\nu \Gamma^{\mu}_{\nu \mu} = \nabla_{\mu} V^{\mu} 
\end{align*}
\end{theorem}
\noindent
A very important corollary is where we take $V^\mu = \nabla^{\mu} F = \partial^\mu F = g^{\mu \nu} \partial_{\nu} F$ where $F$ is a scalar. This is a type $(1,0)$ tensor so we can apply the Voss-Weyl formula,
\[ \nabla_\mu \nabla^\mu F = \frac{1}{\sqrt{g}} \partial_\mu ( \sqrt{g} \, g^{\mu \nu} \partial_\nu F ) \]
This gives an explict formula for the covariant Laplacian, $\nabla^2 = \nabla_\mu \nabla^\mu$ which does not require evaluating the Christoffel symbols. When doing computations, the Voss-Weyl formula is far more convenient to evaluate than proceeding from the definition of the covariant derivative. For example,

(SPHEREICAL) 

\section{Intrinsic Curvature}

\subsection{Parallel Transport}



\subsection{Geodesics}

A Geodesic is the notion of the ``straightest possible'' path on a manifold which may be curved in some nontrivial way. There are two different ways to capture the idea of a path being straight. We could call a path between two points ``straight'' if it minimizes the distance between the points. There is a slight subtlety here which is that we don't just want paths that minimize the distance but actually any path for which any \textit{nearby} path (such that the difference between the two is always small) is longer. We call such a path ``extremal'' because it is a local extremum of the distance function rather than minimal. 
In flat space, minimizing and extremalizing the distance is the same. However, consider two points on a sphere. In general, there are two ``straight'' great circle segments which join the points going opposite ways around the sphere. Only one of these two paths will be the global minimum distance. However, we would like to call both paths geodesics. I will call this the global definition of a geodesic because knowing that a path extremalizes the distance between two points requires global knowledge of the path as a whole. In symbols,  a path $\gamma^\mu(\lambda)$ parametrized by $t$ is a geodesic if,
\[ \delta \int \sqrt{g_{\alpha \beta} \d{x}^\alpha \d{x}^\beta} = \delta \int \sqrt{g_{\alpha \beta} \deriv{\gamma^\alpha}{\lambda} \deriv{\gamma^\beta}{\lambda}} \d{\lambda} = 0 \]
which says that if you make small variations away from the actual geodesic the variation in the path length\footnote{Remember the squared distance of a small displacement is given by $g_{\alpha \beta} \d{x^\alpha} \d{x^\beta}$ so the entire distance is the integral of the square root of this quantity along the path.}.
\par
There is also a local criterion for what it means for a path to be straight. A geodesic is a path that parallel transports its own tangent vector. This is the statement that a geodesic is a path which accelerates as little as possible in the sense that the tangent vector stays in the same direction as much as possible. The best way to visualize this local criterion for being a geodesic is to imagine a car driving along the surface. The path the car takes if we lock the steering wheel dead ahead so the car turns as little as possible as it goes over the curved terain is a geodesic. The local criterion for a path $\gamma^\mu(\lambda)$ to be a geodesic is that the tangent vector $t^i = \deriv{\gamma^\mu}{\lambda}$ is parallel transported along the curve. This requires that,
\[ \nabla_{\gamma(\lambda)} t^{\mu} = \deriv{t^\mu}{\lambda} +  \Gamma^\mu_{\alpha \beta} t^\alpha t^\beta  = 0\] 
This is known as the geodesic equation. A beautiful and important fact is that the global and local definitions of a geodesic are equivalent.\footnote{The proof of this fact uses calculus of variations. See Appendix A. for the derivation of the geodesic equation from extremalizing the total distance along the curve.} Writing out the tangent vector explicitly,
\[ \nderiv{2}{\gamma^\mu}{\lambda} + \Gamma^{\mu}_{\alpha \beta} \deriv{\gamma^\alpha}{\lambda} \deriv{\gamma^\beta}{\lambda}  = 0\]
In general relativity, particles not under the influence of external forces follow geodesics in spacetime. This can be taken as an axiom or can be argued from the equivalence principle. The idea is that a particle without external forces (exluding gravity of course) should accelerate as little as possible. This is how we should tink of a geodesic. In fact, we cannot force the particle's trajectory to have zero acceleration,
\[ \nderiv{2}{\gamma^\mu}{\lambda} = 0\]
in all reference frames because the quantity $\deriv{t^i}{\lambda}$ is not a tensor. However, we can get close. We will now use a common trick in general relativity which is to evaluate some quantity we care about in a \textit{local inertial reference frame} about some point of interest. A local intertial reference frame or LIF is the ``flattest possible'' reference frame at a certain point. Imagine taking the surjace and gluing a flat sheet of paper with a cartesian coordinate system on it to some point $x_0$. This sheet of paper represents the tangent space at $x_0$. Now we glue the entire sheet to the surface while streching it as little as possible. Anyone who has tried to make a map from a globe knows that this is impossible without streching the coordinate system due to the intrinsic curvature of the surface. However, we do get something from an LIF because we fix $g_{\mu\nu}(x_0) = \eta_{\mu \nu}$ the metric at the point of interest is exactly that of the flat tangent space and the Christoffel symbols at $x_0$ all  vanish because to first order the metric is constant at $x_0$. However, as we will see shortly, we cannot make the second derivatives of the metric, or equivalently the first derivatives of the Christoffel symbols, vanish as well because of the nonzero intrinsic curvature which is invariant under changes of coordinate system. Consider a point $x_0$ on the trajectory of a particle in spacetime. In an LIF at $x_0$, we know that $\Gamma^{\mu}_{\alpha \beta} = 0$ therefore, 
\[ \nderiv{2}{\gamma^\mu}{\lambda} + \Gamma^{\mu}_{\alpha \beta} \deriv{\gamma^\alpha}{\lambda} \deriv{\gamma^\beta}{\lambda} = \nderiv{2}{\gamma^\mu}{\lambda} = 0\]
so the geodesic equation reduces to the statement that the coordinate acceleration is zero in a LIF. In fact, we know this must be true from the equivalence principle which tells us that a particle in freefall ``feels'' no acceleration. A frame in freefall is an LIF because by the equivalence principle it looks exactly like flat space close to the point of interest. Therefore, 
the equivalence principle tells us that,
\[  \nderiv{2}{\gamma^\mu}{\lambda} = 0 \implies \nderiv{2}{\gamma^\mu}{\lambda} + \Gamma^{\mu}_{\alpha \beta} \deriv{\gamma^\alpha}{\lambda} \deriv{\gamma^\beta}{\lambda}  = 0\]
because the Christoffel symbols vanish in an LIF. Thus, the geodesic equation holds in these specific coordinates. However, the geodesic equation is a equivalent to $\nabla_{\gamma(\lambda)} t^\mu = 0$ which is a tensor equation. Therefore, if the geodesic equation holds in any coordinate system, it holds in all coordinate systems. The equivalence principle is enough to give us this equation in a specific reference frame and then the power of the tensor property means it must be true in all reference frames. 
\par
The geodesic equation is the fundamental law governing the motion of a particle in curved spacetime. We can write it in a somewhat more suggestive manner,
\[  m \nderiv{2}{\gamma^\mu}{\lambda} = m a^{\mu} = - m \Gamma^{\mu}_{\alpha \beta} \deriv{\gamma^\alpha}{\lambda} \deriv{\gamma^\beta}{\lambda} \] 
where $m$ is the mass of the particle and,
\[ a^\mu = \nderiv{2}{\gamma^\mu}{\lambda} \]
is the \textit{coordinate acceleration}. This looks a lot like Newton's second law with a force,
\[ F^{\mu}_{\mathrm{grav}} = - m \Gamma^{\mu}_{\alpha \beta} \deriv{\gamma^\alpha}{\lambda} \deriv{\gamma^\beta}{\lambda}\]
Thus the Christoffel symbols take on an interpretation as the gravitational force. 
We see that the gravitational force is proportional to the mass or equivalently that the gravitational acceleration is independent of the mass a fundamental observation which lead Einstein to the equivalence principle. In the formalism of GR, adding this factor of $m$ is actually extraneous and only done to make analogies to Newtonian physics.   

\subsection{Geodesic Deviation}

An second notion of what it means for a space to be curved is to consider nearby geodesics. In flat space, geodesics are sraight lines and two parallel lines remain parallel forever and do not intersect. However, on a sphere, two great circles always intersect even if they look parallel at a given point. The fact that parallel geodesics converge or diverge is a manifestation of the intrinsic curvature of the manifold. Furthermore, we will be able to extract an invariant measure of this curvature, the Riemann tensor, from the behvior of nearby geodesics.
\par 
Consider two geodesic paths $x^\mu(\lambda)$ and $\bar{x}^{\mu}(\lambda)$ each satisfying the geodesic equation, 
\[ \nderiv{2}{x^\mu}{\lambda} +  \Gamma^\mu_{\alpha\beta}(x^\mu) t^\alpha t^\beta = 0 \quad \text{and} \quad  \nderiv{2}{\bar{x}^\mu}{\lambda} + \Gamma^\mu_{\alpha\beta}\left(\bar{x}^\mu\right)\bar{t}^\alpha\bar{t}^\beta = 0\]
Let us define a new tensor $\xi^mu$ as:
\[\xi^\mu(\lambda) = \bar{x}^\mu(\lambda) -x^\mu(\lambda)\]
In this case, $\bar x$ and $x$ will only transofrm the same way if their difference is infinitesimal.  Thus, $\xi^\mu$ is a tensor.
We expand in a Taylor series, $\Gamma\left(\bar{x}^\mu\right) = \Gamma(x^\mu) + \xi^\nu \partial_\nu \Gamma(x^\mu) + O(\xi^2)$. The higher order terms are negligable for small $\xi$. Therefore, via substituting into the geodesic, equation for $\bar{x}$ we get,
\begin{align*}
\nderiv{2}{\bar{x}^\mu}{\lambda} + \Gamma^\mu_{\alpha\beta}\left(\bar{x}^\mu\right)\bar{t}^\alpha\bar{t}^\beta 
&  = \partial_\lambda^2 \left(x^\mu + \xi^\mu\right) + \left(\Gamma^\mu_{\alpha\beta}+\xi^\nu \partial_\nu \Gamma^\mu_{\alpha\beta}\right) \partial_\lambda\left(x^\alpha + \xi^\alpha\right)\partial_\lambda\left(x^\beta + \xi^\beta\right)
\\
& = \partial_\lambda^2 \xi^\mu + \Gamma^\mu_{\alpha\beta}\left(\partial_\lambda x^\alpha \partial_\lambda \xi^\beta + \partial_\lambda x^\beta \partial_\lambda \xi^\alpha\right) + \xi^\nu \partial_\nu\Gamma^\mu_{\alpha\beta} \partial_\lambda x^\alpha \partial_\lambda x^\beta
\\
& \quad + \partial_\lambda^2 x^\mu  + \Gamma^\mu_{\alpha\beta} \partial_\lambda x^\alpha \partial_\lambda x^\beta + O(\xi^2)
\\
& = 0
\end{align*}
However, because $x^\mu$ also satisfies the geodesic equation,
\[ \partial_\lambda^2 x^\mu + \Gamma_{\alpha \beta}^\mu \partial_\lambda x^\alpha \partial_\lambda x^\beta = 0\]
the last line of the above equation is zero to first order in $\xi$.  
Therefore, 
\begin{align*} 
& \partial_\lambda^2 \xi^\mu + \Gamma^\mu_{\alpha\beta}\left(\partial_\lambda x^\alpha \partial_\lambda \xi^\beta + \partial_\lambda x^\beta \partial_\lambda \xi^\alpha\right) + \xi^\nu \partial_\nu\Gamma^\mu_{\alpha\beta} \partial_\lambda x^\alpha \partial_\lambda x^\beta  
\\
& = 
\partial_\lambda^2 \xi^\mu + 2 \Gamma^\mu_{\alpha\beta} \partial_\lambda x^\alpha \partial_\lambda \xi^\beta  + \xi^\nu \partial_\nu\Gamma^\mu_{\alpha\beta} \partial_\lambda x^\alpha \partial_\lambda x^\beta = 0 
\end{align*}
where I have used the fact that $\Gamma^\mu_{\alpha \beta} = \Gamma^\mu_{\beta \alpha}$. Thus, we have the differential equation for $\xi$,
\[\partial_\lambda^2 \xi^\mu + 2 \Gamma^\mu_{\alpha\beta} t^\alpha \partial_\lambda \xi^\beta + t^\alpha t^\beta \xi^\nu \partial_\nu\Gamma^\mu_{\alpha\beta} = 0\]
To write this in tensor form, we calculate the double derivative along the curve $x^\mu(\lambda)$, 
\begin{align*}
D_\lambda^2 \xi^\mu = \nabla_{x^\mu(\lambda)}\left(\nabla_{x^\mu(\lambda)}\xi^\mu\right) & = \partial_\lambda^2\xi^\mu + \partial_\lambda\left[\xi^\alpha t^\beta \Gamma^\mu_{\alpha\beta}\right] + \left(\partial_\lambda \xi^\delta + \xi^\alpha t^\beta \Gamma^\delta_{\alpha\beta}\right) t^\gamma\Gamma^\mu_{\gamma\delta}
\\
& = \partial_\lambda^2 \xi^\mu + 2t^\alpha \partial_\lambda \xi^\beta \Gamma^\mu_{\alpha\beta} + \xi^\alpha \partial_\lambda t^\beta \Gamma^\mu_{\alpha\beta} + \xi^\alpha t^\beta \partial_\lambda \Gamma^\mu_{\alpha \beta} + \xi^\alpha t^\beta t^\gamma \Gamma^\delta_{\alpha\beta}\Gamma^\mu_{\gamma \delta}
\end{align*}
Now we use the facts that, $\partial_\lambda t^\beta + t^\rho t^\sigma \Gamma^\beta_{\rho\sigma} = 0$ and $\xi^\alpha t^\beta \partial_\lambda \Gamma^\mu_{\alpha \beta} = \xi^\alpha t^\beta t^\gamma \partial_\gamma \Gamma^\mu_{\alpha \beta}$ we get,
\begin{align*}
D_\lambda^2 \xi^\mu = \partial_\lambda^2 \xi^\mu + 2t^\alpha \partial_\lambda \xi^\beta \Gamma^\mu_{\alpha\beta} + \xi^\alpha \left( - t^\rho t^\sigma \Gamma_{\rho \sigma}^\beta \right) \Gamma^\mu_{\alpha\beta} + \xi^\alpha t^\beta t^\gamma \partial_\gamma \Gamma^\mu_{\alpha \beta} + \xi^\alpha t^\beta t^\gamma \Gamma^\delta_{\alpha\beta}\Gamma^\mu_{\gamma \delta}
\end{align*}
Subtracting the first equation, we find that, 
\begin{align*}
D_\lambda^2 \xi^\mu & = -\xi^\nu t^\alpha t^\beta \partial_\nu \Gamma^\mu_{\alpha\beta} + \xi^\alpha t^\beta t^\gamma \partial_{\gamma}\Gamma^\mu_{\alpha\beta} - \xi^\alpha t^\rho t^\sigma \Gamma^\beta_{\rho\sigma}\Gamma^\mu_{\alpha\beta} + \xi^\alpha t^\beta t^\gamma\Gamma^\delta_{\alpha\beta}\Gamma^\mu_{\gamma_\delta}
\\
& = - \xi^\nu t^\alpha t^\beta \left( \partial_{\nu} \Gamma^\mu_{\alpha \beta} - \partial_{\beta} \Gamma^\mu_{\nu \alpha} + \Gamma^{\delta}_{\alpha \beta} \Gamma^{\mu}_{\nu \delta} - \Gamma^\delta_{\nu \alpha} \Gamma^\mu_{\beta \delta} \right)
\end{align*}
Because the left hand side is a tensor since the covariant derivative produces tensors and we have shown equality in any coordinate systems, the right hand side must also be a tensor. This motivates Riemann's definition of the curvature tensor. 
\subsection{The Riemann Tensor}

\begin{definition}
The Riemann Tensor defined as, 
\[R^\mu_{\alpha \nu \beta} = \partial_{\nu} \Gamma^\mu_{\alpha \beta} - \partial_{\beta} \Gamma^\mu_{\nu \alpha} + \Gamma^{\delta}_{\alpha \beta} \Gamma^{\mu}_{\nu \delta} - \Gamma^\delta_{\nu \alpha} \Gamma^\mu_{\beta \delta} \]
\end{definition}
\noindent
Using this notation, our equation for geometric deviation becomes,
\[ D_\lambda^2 \xi^\mu + \xi^\nu t^\alpha t^\beta R^\mu_{\alpha \nu \beta} = 0\]
Therefore, parallel geodesics generically remain parallel only when $R^\mu_{\alpha \nu \beta} = 0$. This justifies calling any space with $R^\mu_{\alpha \nu \beta} = 0$ flat.
\\
In locally intertial frames, The Christoffel symbols vanish at $x_0^\mu$, and using the fact that, $\Gamma^\mu_{\alpha\beta} = \frac{1}{2}g^{\mu\nu}\left(\partial_\alpha g_{\beta\nu}+\partial_\beta g_{\alpha\nu} - \partial_\nu g_{\alpha\beta}\right)$, 
we find, 
\begin{align*}R^\mu_{\alpha\beta\gamma}&\left(x^\mu_0\right) = \partial_\beta\Gamma^\mu_{\alpha\gamma} - \partial_\gamma\Gamma^\mu_{\alpha\beta}
\\
\implies R_{\mu\alpha\beta\gamma} &(x^\mu_0) = \frac{1}{2}\left(\partial_\beta \partial_\alpha g_{\gamma\mu} + \partial_\beta \partial \gamma g_{\alpha\mu} - \partial_\beta \partial_\mu g_{\alpha\gamma} - \partial_\gamma\partial_\alpha g_{\beta\mu} - \partial_\gamma\partial_\beta g_{\alpha\mu} + \partial_\gamma\partial_\mu g_{\alpha\beta}\right)
\\
\implies  R_{\mu\alpha\beta\gamma} &(x^\mu_0) =\frac{1}{2}\left(\partial_\beta\partial_\alpha g_{\gamma\mu} + \partial_\gamma\partial_\mu g_{\alpha\beta} - \partial_\beta\partial_\mu g_{\alpha\gamma} - \partial_\gamma\partial_\alpha g_{\beta\mu}\right)
\end{align*}
Remember!  This result only holds in an LIF.
\subsubsection{Properties of the Riemann Tensor}
In a LIF, we found above, that,  
\[R_{\alpha\beta\gamma\delta} (x^\mu_0) = \frac{1}{2}\left(\underbrace{\partial_\gamma\partial_\beta g_{\alpha\delta}}_{(1)} + \underbrace{\partial_\alpha\partial_\delta g_{\beta\gamma}}_{(2)}- \underbrace{ \partial_\gamma\partial_\alpha g_{\beta\gamma} }_{(3)}-\underbrace{ \partial_\delta\partial_\beta g_{\alpha\gamma}}_{(4)}\right)\]
We note that there are specific symmetries in exchanging indices. In other words, in swapping the greek indices we find that terms switch roles:
\[\alpha \leftrightarrow \beta \implies \text{ Term $(1)$} \leftrightarrow \text{ Term $(3)$} \text{ and } \text{ Term $(2)$} \leftrightarrow \text{ Term $(4)$}\]
\[ \gamma\leftrightarrow \delta \implies \text{ Term $(1)$} \leftrightarrow \text{ Term $(4)$} \text{ and } \text{ Term $(2)$} \leftrightarrow \text{ Term $(3)$}\]
Therefore, we get the property that, 
\[R_{\alpha\beta\gamma\delta} = -R_{\beta\alpha \gamma\delta} =-R_{\alpha\beta\delta\gamma} = R_{\beta \alpha \delta \gamma}\]
Similarly, 
\[\ \alpha\leftrightarrow \gamma \quad \text{and} \quad \beta\leftrightarrow\delta \implies \text{ Term $(1)$} \leftrightarrow \text{ Term $(2)$} \text{ and } \text{ Term $(3)$} \leftrightarrow \text{ Term $(4)$}\]
which implies that, 
\[R_{\alpha\beta\gamma\delta} = R_{\gamma\delta\alpha\beta} = R_{\delta\gamma\beta \alpha} = -R_{\delta\gamma\alpha\beta} = - R_{\gamma\delta\beta\alpha}\]
Next, consider, at $x_0$,
\begin{align*}
R_{\alpha \beta \gamma \delta} & = \tfrac{1}{2}\left( \partial_\gamma\partial_\beta g_{\alpha\delta} + \partial_\alpha\partial_\delta g_{\beta\gamma} - \partial_\gamma\partial_\alpha g_{\beta\gamma} - \partial_\delta\partial_\beta g_{\alpha\gamma} \right)
\\
R_{\alpha \gamma \delta \beta} & = \tfrac{1}{2}\left( \partial_\delta \partial_\gamma g_{\alpha\beta} + \partial_\alpha\partial_\beta g_{\gamma\delta} - \partial_\delta\partial_\alpha g_{\gamma\delta} - \partial_\beta\partial_\gamma g_{\alpha\delta} \right)
\\
R_{\alpha \delta \beta \gamma} & = \tfrac{1}{2}\left( \partial_\beta\partial_\delta g_{\alpha\gamma} + \partial_\alpha\partial_\gamma g_{\delta\beta} - \partial_\beta\partial_\alpha g_{\delta\beta} - \partial_\gamma\partial_\delta g_{\alpha\beta} \right) 
\end{align*}
Let $(a, b)$ refer to the $b^{\text{th}}$ term of the $a^{\text{th}}$ line. Now,
\begin{enumerate}
\item (1,1) and (2,4) cancel
\item (1,2) and (2,3) cancel
\item (1,3) and (3,2) cancel
\item (1,4) and (3,1) cancel
\item (2,1) and (3,4) cancel
\item (2,2) and (3,3) cancel
\end{enumerate}
Therefore, all terms cancel to zero leving,
\[ R_{\alpha \beta \gamma \delta} + R_{\alpha \gamma \delta \beta} + R_{\alpha \delta \beta \gamma} = 0 \]
which is known as the \textbf{First or Arithmetic Bianchi Identity}.
\subsubsection{Bianci Identity}
In LIF, we recall that $\nabla_\mu = \partial_\mu$ when evaluated at $x^\mu _0$.  Now, let us introduce the notation, $\partial_{\alpha\beta} = \partial_\alpha\partial_\beta$.  From the definition of the Riemann Tesnor along and the gradient in LIF, we have, 
\begin{align*}
\nabla_\epsilon R_{\alpha\beta\gamma\delta} &= \tfrac{1}{2}\left(\partial_{\epsilon\gamma\beta} g_{\alpha\delta} + \partial_{\epsilon\alpha\delta} g_{\beta\gamma} - \partial_{\epsilon\gamma\alpha}g_{\beta\delta} - \partial_{\epsilon\delta\beta}g_{\alpha\gamma}\right)
    \\
\nabla_\gamma R_{\alpha\beta\delta\epsilon} &= \tfrac{1}{2}\left(\partial_{\gamma\delta\beta} g_{\alpha\epsilon} + \partial_{\gamma\alpha\epsilon} g_{\beta\delta} - \partial_{\gamma\delta\alpha}g_{\beta\epsilon} - \partial_{\gamma\epsilon\beta}g_{\alpha\delta}\right)
    \\
\nabla_\delta R_{\alpha\beta\epsilon\gamma} &= \tfrac{1}{2}\left(\partial_{\delta\epsilon\beta} g_{\alpha\gamma} + \partial_{\delta\alpha\gamma} g_{\beta\epsilon} - \partial_{\delta\epsilon\alpha}g_{\beta\gamma} - \partial_{\delta\gamma\beta} g_{\alpha\epsilon}\right)
\end{align*}
Now,
\begin{enumerate}
\item (1,1) and (2,4) cancel
\item (1,2) and (3,3) cancel
\item (1,3) and (2,2) cancel
\item (1,4) and (3,1) cancel
\item (2,1) and (3,4) cancel
\item (3,2) and (2,3) cancel
\end{enumerate}
These terms all cancel out just right so that the sum vanishes. This gives the \textbf{Second or Differential Bianchi Identity},
\begin{equation} \label{Bianchi}
\nabla_\epsilon R_{\alpha\beta\gamma\delta} + \nabla_\gamma R_{\alpha\beta\delta\epsilon} + \nabla_\delta R_{\alpha\beta\epsilon\gamma}  = 0
\end{equation}
We note that these derivations assumed that we were working in a LIF, but since they are tensor identities, they are true in any coordinates.

\subsection{Ricci Curvature}
We now define the Ricci Curvature tensor
\begin{definition}
The Ricci Tensor, $R_{\mu\nu}$ is defined as, 
\[R_{\mu\nu} = R^\alpha _{\mu\alpha\nu} = g^{\alpha\gamma} R_{\alpha\mu\gamma\nu} = g^{\gamma\alpha} R_{\gamma\nu\alpha\mu} = R_{\nu \mu}\]
We therefore have from above that the Ricci Tensor is symmetric.
\end{definition}
\begin{definition}
From the Ricci Tensor, we define the Ricci Curvature scalar as, 
\[R = R^\mu_\mu = g^{\mu\nu} R_{\mu\nu}\]
\end{definition}
From these definitions, we get the following lemma:
\begin{lemma}
\[\nabla_\mu R^\mu_\nu  = \frac{1}{2}\nabla_\nu R\]
\begin{proof}
We begin with the Bianchi identity as in \ref{Bianchi} and contract it to get, 
\[g^{\beta\delta} g^{\alpha\gamma}\left(\nabla_\epsilon R_{\alpha\beta\gamma\delta} + \nabla_\gamma R_{\alpha\beta\delta\epsilon} + \nabla_\delta R_{\alpha\beta\epsilon\gamma} \right) = 0\]
We contract and get, 
\begin{align*}
    0 &g^{\beta\delta} g^{\alpha\gamma}\left(\nabla_\epsilon R_{\alpha\beta\gamma\delta} + \nabla_\gamma R_{\alpha\beta\delta\epsilon} + \nabla_\delta R_{\alpha\beta\epsilon\gamma} \right) 
    \\
    & = g^{\beta\gamma}\left(\nabla_\mu R_{\beta\delta} + \nabla^\gamma R_{\gamma\beta\delta\mu} + \nabla_{\delta} R^\gamma_{\beta\mu\gamma}\right)
    \\
    & = \nabla_\mu R^\delta_\delta + \nabla_\gamma R^{\delta\gamma}_{\delta\mu} - \nabla_\delta R^\delta_\mu
\end{align*}
Thus, solving for $\nabla_\mu R$
\[\nabla_\mu R = \nabla_\gamma R^\gamma_\mu + \nabla_\delta R^\delta_\mu\implies \nabla_\mu R^\mu_\nu = \frac{1}{2}\nabla_\nu R\]
where we took advantage of substituting dummy variables.
\end{proof}
\end{lemma}
\noindent
As a corollary, we find, 
\[\nabla_\mu R^{\mu\nu} = \frac{1}{2}g^{\mu\nu}\nabla_\mu R\]


\section{The Einstein Field Equations}

\subsection{Motivation}

\subsection{Einstein-Hilbert Action}

David Hilbert, one of the greatest mathematicians of the $20^{\mathrm{th}}$ century showed that the field equations of general relativity could be obtained by minimizing a beautifully simple action. We consider all possible metrics and compute some number called the action for each of possible metric. We want to find a metric which extremalizes this action. It turns out that the condition that a metric extremalizes some action will be that it satisfies some field equation. If we start with an invariant action, then we must derive conditions which satisfy the principle of general covariance because they must have the same form in any reference frame. A truly remarkable fact about general relativity is that the action which gives rise the Einstein field equations is the simpliest possible curvature invariant we can cook up. It turns out that satisfying the Einstein field equations is exactly the condition for a metric to minimize (really extremalize) the total Ricci curvature scalar. If there is matter than we want the metric which extremalizes the difference between the Lagrangian density of the matter and the Ricci scalar.
\par   
We begin to construct the Einstein-Hilbert action by first considering an invariant volume.  In normal cartesian coordinates, the infinitesimal volume of a parallelogram with sides $\d x_1^\mu, \d x_2^\mu, \d x_3^\mu, \d x_2^\mu$, is $S_{ijkl} \d x_1^i \d x_2^j \d x_3^k \d x_4^l$ where $S$ is the symmetry symbol.  We may makes this quantity invariant by defining the volume element of the same parallelogram as, 
\[\d{V} = \epsilon_{ijkl} \d{x_1}^i \d{x_2}^j \d{x_3}^k \d{x_4}^l\]
Therefore, to integrate over such a volume element, we use a volume element spanned by the four infinitesimal increments in each coordinate: $\d{V} = \sqrt{q} \, \d x^1\d x^2 \d x^3 \d x^4$ which we shall write as $\d V = \sqrt{g} d^4 x$.
\\
The action $S$ defined as, 
\[S = \int \mathcal{L}\sqrt{g} \: \dn{4}{x} \]
is invariant of $\mathcal{L}$ is invariant.  Thus, all laws derived from $S$ will hold in all reference frames.
\begin{definition}[Einstein-Hilbert Action]
This is the simplest action connecting curvature to Matter/Energy is the corresponding action from the
\[\mathcal{L}_{GR}  =-\frac{c^4}{16 \pi G} R + \mathcal{L}_M\]
where $R$ is the Ricci scalar, the simplest invariant of $R_{\alpha\beta\gamma\delta}$.  
\end{definition}
We now proceed to find the functional variation of this Einstein-Hilbert action. For notational convienience\footnote{The strange combination of symbols is a historical accident. If general relativity were discovered first then $\kappa$ rather than $G$ would be called the universal gravitational constant} set $\kappa = \frac{8\pi G}{c^4}$. Now we extreamalize $S$ by setting its variation equal to zero, 
\begin{align*}
\delta S & = 0
\\
& = \delta\left(\int \left[ -\frac{1}{2\kappa} R + \mathcal{L}_M\right]\sqrt{g} \: \dn{4}{x} \right)
= 
\int \left[-\frac{1}{2\kappa}\frac{\delta \sqrt{g} R}{\delta g^{\mu\nu}} +\frac{\delta\sqrt{g}\L_M}{\delta g^{\mu\nu}}\right] \delta g^{\mu\nu} \: \dn{4}{x}
\\
& = \int \left[ -\frac{\delta R}{\delta g^{\mu\nu}} + \frac{R}{\sqrt{g}}\frac{\delta\sqrt{g}}{\delta g^{\mu\nu}} + \frac{2\kappa}{\sqrt{g}} \frac{\delta\sqrt{g}L_M}{\delta g^{\mu\nu}}\right] \delta g^{\mu\nu} \: \dn{4}{x}
\end{align*}
Now, we solve and find, $\delta R$.  
\begin{align*}
    \delta R = \delta R_{\mu\nu} g^{\mu\nu}+ R_{\mu\nu} \delta g^{\mu\nu}
\end{align*}
where, 
\[\delta R_{\mu\nu} = \delta R^\sigma_{\mu\sigma \nu} = \delta\left[\partial_\mu \Gamma^\sigma _{v\sigma} -\partial_\nu \Gamma^\sigma_{\mu\sigma} + \Gamma^\rho_{\sigma \nu}\Gamma^\sigma_{\mu \rho} -\Gamma^\delta _{\mu\sigma} \Gamma^\sigma_{\nu \delta} \right] \]
This may be simplified as, 
(FIX THIS DERIVATION)
\begin{align*}
\delta R_{\mu\nu}& = \partial_\sigma \delta \Gamma^\alpha_{\mu\nu} - \partial_\nu \delta \Gamma^\alpha_{\mu\sigma} + \delta \Gamma^\rho_{\mu\nu} \Gamma^\rho_{\mu\nu} -\delta \Gamma^\delta _{\mu\sigma} \Gamma^\alpha_{\nu\delta} - \Gamma^\delta _{\mu\sigma} \Gamma^\alpha_{\nu\delta}
\\
& = \nabla_\sigma \delta\Gamma^\alpha_{\mu\nu} + \delta \Gamma^\alpha_{\mu\rho} \Gamma^\rho_{\nu\sigma} - \nabla_\nu \delta\Gamma^\alpha_{\mu\sigma} + \delta \Gamma^\alpha_{\mu\rho} \Gamma^\rho _\nu\sigma
\end{align*}
Therefore, we plug this in to find, 
\begin{align*}\delta R& = R_{\mu \nu} \delta g^{\mu\nu} + g^{\mu\nu}\left[\nabla_\sigma \delta \Gamma^\sigma_{\mu\nu} + \nabla_\nu \delta \Gamma^\sigma _{\mu\sigma}\right]
\\
& = R_{\mu\nu}\delta g^{\mu\nu} + \nabla_\sigma \left[g^{\mu\nu}\delta \Gamma^\sigma_{\mu\nu} - g^{\mu\sigma}\delta \Gamma^\sigma_{\mu\sigma}\right]
\end{align*}
We note however that since, $\left(\nabla_\sigma A^\sigma \right)\sqrt{g} = \partial_\sigma \sqrt{g} A^\sigma$, we get, that, 
\[\frac{\delta R}{\delta g^{\mu\nu}} = R_{\mu\nu}\]
Similarly, we find therefore that, 
\[\delta S = \int\left[-R_{\mu\nu} + \frac{1}{2} Rg_{\mu\nu} + \kappa \frac{2}{\sqrt{g}} \frac{\delta \sqrt{g}\mathcal{L_M}}{\delta^{\mu\nu} }\right] \delta g^{\mu\nu} \sqrt{g}\d^4 x\]
this holds for any $\delta g^{\mu\nu}$ and therefore, the integrand is zero.
\\
We now define the Stress-Energy-Momentum Tensor. 
\begin{definition}
The Stress-Energy-Momentum Tensor is defined as, 
\[T_{\mu\nu} = \frac{2}{\sqrt{g}} \frac{\delta\sqrt{g}\mathcal{L_M}}{\delta g^{\mu\nu}}\]
We note that this tensor is symmetric such that, $T_{\mu\nu} = T_{\nu\mu}$
\end{definition}
Substituting into the above condition we get by setting the variation of the Einstein-Hilbert action to 0, we get the equation, 
\[R_{\mu\nu} -\frac{1}{2}R g_{\mu\nu} = \frac{8\pi G}{c^4}T_{\mu\nu}\]
Therefore, taking the gradient  with respect to $\mu$ of each side, we find that the equations of motion imply, 
\[\nabla_\mu T^{\mu\nu} = 0\]

\subsection{Properties of the Field Equations}

Now we have the fundamental law of general relativity which describes the shape of spacetime,
\[ R_{\mu \nu}  - \frac{1}{2} R g_{\mu \nu} = \frac{8\pi G}{c^4} T_{\mu \nu}\] 
The energy-momentum tensor acts as a source term for this set of coupled differential equations. The left hand size of the field equations is a function of $R_{\mu \nu}$ which is built from the Riemann tensor which is built from the Christoffel symbols which themselves are built from the metric and its derivatives. Therefore, the Einstien field equations give us a set of differential equations which can be used to, in principle, compute the metric everywhere. Once we know the metric, we can find the geodesics and therefore know everything about the spacetime geometry we could think to ask. However, this is an extremely difficult calculation to do even in simple cases and effectively impossible in general. Therefore, we will put quite a bit of effort into finding approximate solutions to the field equations and to exctracting information from them without writing down an explicit solution for the metric. 
\par
First, from the properties of the geometric objects on the left, we can deduce properties of the energy-momentum tensor which must be satisfied if Einstein's equations are to hold. For example, we know that,
\[G_{\mu \nu} = R_{\mu \nu} - \tfrac{1}{2} R g_{\mu \nu} \]
is a symmetric tensor because both $R_{\mu \nu}$ and $g_{\mu \nu}$ are. Thus, any valid stress-energy tensor $T_{\mu \nu}$ must be symmetric as well if Einstein's field equations are satisfied. Furthermore, we want the energy-momentum tensor to satisfy a local conservation equation,
\[ \nabla_{\mu} T^{\mu \nu} = 0 \]
which is immediate for true solutions of the field equations for the metric (metrics that extremalized the Einstein-Hilbert action) because,
\[ \nabla_\mu R^{\mu \nu} = \tfrac{1}{2} g^{\mu \nu} \nabla_\mu R = \tfrac{1}{2} \nabla_\mu (R g^{\mu \nu}) \implies \nabla_\mu G^{\mu \nu} = 0\]
This property of the geometric objects was part of Einstein's origional motivation for the form of the field equations. 
\par 
Taking the trace of the field equations,
\[ R - \tfrac{1}{2} R g^{\mu \nu} g_{\mu \nu} = \frac{8 \pi G}{c^4} T^{\mu}_{\mu} \]
Denoting the energy-momentum trace, $T = T^{\mu}_{\mu}$ and seeing that $g^{\mu \nu} g_{\mu \nu} = \delta^\mu_{\mu} = n = 4$ we get that,
\[ R - 2 R = \frac{8 \pi G}{c^4} T \implies R = - \frac{8 \pi G}{c^4} T \]
Therefore, we can swap $R$ with $T$ in the Einstein field equations to get,
\[ R_{\mu \nu} = \frac{8 \pi G}{c^4} (T_{\mu \nu} - \tfrac{1}{2} T g_{\mu \nu}) \]
Suppose we consider the gravitational field in a vacuum, no matter or energy anywhere such that $T_{\mu \nu} = 0$. Using the above relations, $T = R = 0$ so Einstein's field equations reduce to $R_{\mu \nu} = 0$. Therefore, ``vacuum solutions'' to Einstein's field equations are exactly those metrics which give rise to vanishing Ricci curvature $R_{\mu \nu}$. However, this does not mean that a vacuum solution is necessarily flat. It turns out that the Ricci tensor vanishing, $R_{\mu \nu} = 0$, does not imply that the Riemann curvature tensor $R_{\alpha \beta \gamma \delta}$ also vanishes, only that its partial traces are all zero. Therefore, we can have vacuum solutions with nontrivial Riemannian curvature and thus interesting geometry. This fact is very important because it allows for gravitational waves to propagate though a vacuum. We will spend quite a lot of time working with vaccum solutions in the comming sections. 

\section{The Newtonian Limit}

We want to consider gravity in the weak field limit meaning when gravity is very weak and therefore the metric is approximatly flat. We can choose almost Minkowski coordinates such that $g_{\mu \nu} = \eta_{\mu \nu} + h_{\mu \nu}$ where we thing of $h_{\mu \nu}$ as being a small perturbation away from being flat.

\section{Black Holes: The Schwarzschild Metric}

\subsection{Deriving the Metric}

We want to find a spherically symmetric vacuum solution to Einstein's field equations in the empty space surrounding a compact massive object. We can always choose an orthogonal coordinate system in which the basis vectors are orthogonal and therefore the metric is diagonal everywhere. Since we require the solution to have spherical symmetry, we will proceed by generalizing the metric for spherical coordinates $(t, r, \theta, \phi)$,
\[ g^{\mathrm{sph.}}_{\mu \nu}
= 
\begin{pmatrix}
c^2 & 0 & 0 & 0 \\
0 & -1 & 0 & 0 \\
0 & 0 & - r^2 & 0 \\
0 & 0 & 0 & - r^2 \sin^2{\theta}
\end{pmatrix}
\]
By spherical symmetry and time translation invariance, that is we want the solution to be static in time, we want the metric to only be a function of $r$. Therefore, we can write,
\[ g_{\mu \nu}
= 
\begin{pmatrix}
c^2 A(r) & 0 & 0 & 0 \\
0 & -B(r) & 0 & 0 \\
0 & 0 & - r^2 & 0 \\
0 & 0 & 0 & - r^2 \sin^2{\theta}
\end{pmatrix}
\]
where $A$ and $B$ are yet undetermined functions of $r$. One might wonder why we only let the first two terms depend on arbitrary functions of $r$. By spherical symmetry, the last two terms representing the interval along a sphere in terms of the angles $\theta$ and $\phi$ must be of the form, 
\[C(r) \d{\Omega}^2 = C(r) r^2 ( \d{\theta}^2 + \sin^2{\theta} \, \d{\phi}^2)\] 
since otherwise there would be prefered directions on the sphere. However, in this case we can simply redefine the coordinate $r$ such that $r'^2 = C(r) r^2$ and therefore the metric can be put in the above form. We can next scale the time component to fix the determinant of the metric. It is convinient to choose,
\[ \det{g_{\mu \nu}} = - c^2 r^4 \sin^2{\theta} \]
which is the determinant of the metric for flat spherical coordinates. However,
\[ \det{g_{\mu \nu}} = - c^2 A(r) B(r) r^4 \sin^2{\theta} \]
so our determinant condition forces $B(r) = 1/A(r)$. 

\subsection{The Christoffel Symbols and the Ricci Tensor}

Now we need to calculate the Christoffel symbols. This is a tedious and horrible excercise which Mathematica is perfectly suited for. Therefore, I will simply quote the results,
\[
\Gamma^t_{\alpha \beta} = 
\begin{pmatrix}
0 & \frac{A'(r)}{2 A(r)} & 0 & 0 \\
\frac{A'(r)}{2 A(r)} & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0
\end{pmatrix}
\quad \quad 
\Gamma^r_{\alpha \beta} = 
\begin{pmatrix}
\tfrac{1}{2} c^2 A'(r) A(r) & 0 & 0 & 0 \\
0 & - \frac{A'(r)}{2 A(r)} & 0 & 0 \\
0 & 0 & - r A(r) & 0 \\
0 & 0 & 0 & - r A(r) \sin^2{\theta}
\end{pmatrix}
\]
\[
\Gamma^\theta_{\alpha \beta} = 
\begin{pmatrix}
0 & 0 & 0 & 0 \\
0 & 0 & \frac{1}{r} & 0 \\
0 & \frac{1}{r} & 0 & 0 \\
0 & 0 & 0 & - \cos{\theta} \sin{\theta} \\
\end{pmatrix}
\quad \quad 
\Gamma^r_{\alpha \beta} = 
\begin{pmatrix}
0 & 0 & 0 & 0 \\
0 & 0 & 0 & \frac{1}{r} \\
0 & 0 & 0 & \frac{\cos{\theta}}{\sin{\theta}} \\
0 & \frac{1}{r} & \frac{\cos{\theta}}{\sin{\theta}} & 0 \\
\end{pmatrix}
\]
Next we need to calculate the Ricci tensor,
\[ R_{\mu \nu} = \partial_{\alpha} \Gamma^{\alpha}_{\mu \nu} - \partial_{\nu} \Gamma^{\alpha}_{\alpha \mu} + \Gamma^{\beta}_{\mu \nu} \Gamma^{\alpha}_{\alpha \beta} - \Gamma^{\beta}_{\alpha \mu} \Gamma^{\alpha}_{\nu \beta} \] 
again, this is a terrible and boring calculation which I will let Mathematica chew on. The result is,
\[
R_{\mu \nu} = 
\begin{pmatrix}
\tfrac{1}{2} c^2 A(r) \left( \frac{2 A'(r)}{r} + A''(r) \right) & 0 & 0 & 0 \\ 
0 & - \frac{2 A'(r) + r A''(r)}{2 r A(r)} & 0 & 0 \\
0 & 0 & 1 - A(r) - r A'(r) & 0 \\
0 & 0 & 0 & (1 - A(r) - r A'(r)) \sin^2{\theta} 
\end{pmatrix}
\]
because we are looking for a vaccum solution, we set,
\[ R_{\mu \nu} = 0 \]
Looking at the equation $R_{\theta \theta} = 0$ we get,
\[ 1 - A(r) - r A'(r) = 0 \implies \deriv{}{r} \left( r A(r) \right) = 1 \]
Therefore, the generic solution for $A$ is,
\[ A(r) = \frac{r - r_s}{r} = 1 - \frac{r_s}{r} \]
where $r_s$ is an integration constant. Thus, the metric becomes, 
\newcommand{\sfactor}{\left(1 - \frac{r_s}{r} \right)}

\[ g_{\mu \nu}
= 
\begin{pmatrix}
c^2 \sfactor & 0 & 0 & 0 \\
0 & - \sfactor^{-1} & 0 & 0 \\
0 & 0 & - r^2 & 0 \\
0 & 0 & 0 & - r^2 \sin^2{\theta}
\end{pmatrix}
\]
so the proper time interval can be written as,
\[ c^2 \d{\tau}^2 = \sfactor c^2 \d{t}^2 - \sfactor^{-1} \d{r}^2 - r^2 \d{\Omega}^2 \]
And finally, the Christoffel symbols become,
\[
\Gamma^t_{\alpha \beta} = 
\begin{pmatrix}
0 & \frac{r_s}{2r^2}\sfactor^{-1} & 0 & 0 \\
\frac{r_s}{2r^2}\sfactor^{-1} & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0
\end{pmatrix}\]
\[
\Gamma^r_{\alpha \beta} = 
\begin{pmatrix}
\frac{c^2 \sfactor}{2 r^2} & 0 & 0 & 0 \\
0 & - \frac{r_s}{2r^2}\sfactor^{-1} & 0 & 0 \\
0 & 0 & - (r - r_s) & 0 \\
0 & 0 & 0 & - (r - r_s) \sin^2{\theta}
\end{pmatrix}
\]
\[
\Gamma^\theta_{\alpha \beta} = 
\begin{pmatrix}
0 & 0 & 0 & 0 \\
0 & 0 & \frac{1}{r} & 0 \\
0 & \frac{1}{r} & 0 & 0 \\
0 & 0 & 0 & - \cos{\theta} \sin{\theta} \\
\end{pmatrix}
\quad \quad 
\Gamma^\phi_{\alpha \beta} = 
\begin{pmatrix}
0 & 0 & 0 & 0 \\
0 & 0 & 0 & \frac{1}{r} \\
0 & 0 & 0 & \frac{\cos{\theta}}{\sin{\theta}} \\
0 & \frac{1}{r} & \frac{\cos{\theta}}{\sin{\theta}} & 0 \\
\end{pmatrix}
\]
We can determine the constant $r_s$ from the mass  of the compact object. Using the geodesic equation parametrized by proper time,
\[ \nderiv{2}{x^\mu}{\tau} = - \Gamma^\mu_{\alpha \beta} \deriv{x^\alpha}{\tau} \deriv{x^\beta}{\tau} \]
In particular suppose that $\theta$ and $\phi$ are constant. Then, in the $r$ direction,
\[ a^r = \nderiv{2}{x^r}{\tau} = - \Gamma^r_{\alpha \beta} \deriv{x^\alpha}{\tau} \deriv{x^\beta}{\tau} = -\frac{r_s}{2r^2} \left[  c^2 \sfactor \left( \deriv{t}{\tau} \right)^2 - \sfactor^{-1} \left( \deriv{r}{\tau} \right)^2  \right] \]
However, for $\d{\theta} = \d{\phi} = 0$ we see from the expression for an increment of proper time,
\[ c^2  = c^2 \left( \deriv{\tau}{\tau} \right)^2 =  c^2 \sfactor \left( \deriv{t}{\tau} \right)^2 - \sfactor^{-1} \left( \deriv{r}{\tau} \right)^2 \]
Therefore, the radial acceleration becomes,
\[ a^r  = -\frac{r_s c^2}{2r^2} \]
which has the form of Newton's universal law of gravitation,
\[ a = - \frac{MG}{r^2}\]
Since we want general relativity to reproduce Newton's laws in the low energy limit and we only have one parameter to play with, we are forced to take,
\[ r_s = \frac{2 M G}{c^2} \]
This is known as the Schwarzschild radius. Matching the low energy limit to Newtonain theory may be an unsatisfying argument and if so one can fix the constant $r_s$ by solving Einstein's field equations inside the compact body where $T_{\mu \nu} \neq 0$. However, this is even more difficult and does not give us nearly enough to be worth the trouble. From above, it may seem that general relativity exactly reproduces Newton's law of gravitation but this is not true. Firstly, we derived the acceleration in the special case that $\theta$ and $\phi$ were constant, that is the particle is moving along a radial trajectory. For more general trajectories the acceleration will not have this simple form and the angular momentum will enter the expression. Furthermore, $a^r$ is the acceleration with respect to \textit{proper} time not the \textit{coordinate} acceleration one gets by simply differentiating the coordinte $r$ with respect to the coordinate $t$ twice. That said, in the limit of velocities much less than the speed of light and radii much larger than $r_s$, only the the term $\Gamma^r_{00}$ contributes in the geodesic equation because it has a relative factor of $c^2$ so the acceleration does not depend on angular velocity and the proper and coordinate accelerations agree with eachother and with the Newtonian value.   

\subsection{A Black Hole}  


\subsubsection{Killing Vectors}

Solving the geodesic equation is difficult and annoying. We want to make use of the symmetry of the Schwarchild metric to find conserved quantities of the motion. One method of doing this is to find so called Killing vectors named for Wilhelm Killing.

\begin{definition}
A vector field $K_\mu$ is a Killing field if,
\[ \nabla_{\mu} K_\nu + \nabla_{\nu} K_{\mu} = 0 \]
\end{definition}
Such a vector field is a manifestation of some symmetry of the spacetime. The essential fact about Killing vectors is that they give rise to conserved quantities along geodesics.

\begin{theorem}
Let $K_\mu$ be a killing vector and $x^{\mu}(\lambda)$ a geodesic. Then the quantity,
\[ Q = K_\mu \deriv{x^{\mu}}{\lambda}\]
is conserved along the geodesic. Explicitly,
\[ \deriv{}{\lambda} \left( K_\mu \deriv{x^{\mu}}{\lambda} \right) = 0\]
\end{theorem}

\begin{proof}
Using the geodesic equation,
\begin{align*}
\deriv{}{\lambda} \left( K_\mu \deriv{x^{\mu}}{\lambda} \right) & = \deriv{K_\mu}{\lambda} \deriv{x^{\mu}}{\lambda} + K_\mu \nderiv{2}{x^{\mu}}{\lambda} 
\\
& = \pderiv{K_\mu}{x^{\alpha}} \deriv{x^{\alpha}}{\lambda} \deriv{x^{\mu}}{\lambda} - K_\mu \Gamma^{\mu}_{\alpha \beta} \deriv{x^\alpha}{\lambda} \deriv{x^\beta}{\lambda}
\end{align*}
However,
\[ \nabla_{\mu} K_\nu + \nabla_{\nu} K_{\mu} = 0 \]
and therefore,
\[ \partial_{\mu} K_\nu + \partial_{\nu} K_{\mu} - K_{\alpha} \Gamma^{\alpha}_{\mu \nu} - K_{\alpha} \Gamma^{\alpha}_{\nu \mu} = 0 \]
However, the Christoffel symbol is symmetric so,
\[ \partial_{\mu} K_\nu + \partial_{\nu} K_{\mu} = 2 K_{\alpha} \Gamma^{\alpha}_{\mu \nu} \]
Now we doubly contract both sides of this equation with the tangent vector of the geodesic $t^\mu = \deriv{x^\mu}{\lambda}$ which gives,
\[ \partial_\mu K_\nu t^\mu t^\nu + \partial_{\nu} K_{\mu} t^\mu t^\nu = 2 K_{\alpha} \Gamma^{\alpha}_{\mu \nu} t^{\mu} t^{\nu} \]
The two terms on the right hand side are equal by renaming indices so,
\[ 2 \partial_\mu K_\nu t^\mu t^\nu = 2 K_{\alpha} \Gamma^{\alpha}_{\mu \nu} t^{\mu} t^{\nu} \]
which implies that.
\[ \partial_{\mu} K_{\nu} t^\mu t^\nu = K_{\alpha} \Gamma^{\alpha}_{\mu \nu} t^\mu t^\nu \]
which are, up to renaming summed over incides, exactly the two terms in the derivative of $Q$. Therefore,
\[ \deriv{}{\lambda} \left( K_\mu \deriv{x^{\mu}}{\lambda} \right) = \pderiv{K_\mu}{x^{\alpha}} \deriv{x^{\alpha}}{\lambda} \deriv{x^{\mu}}{\lambda} - K_\mu \Gamma^{\mu}_{\alpha \beta} \deriv{x^\alpha}{\lambda} \deriv{x^\beta}{\lambda} = \partial_{\alpha} K_{\mu} t^\alpha t^\mu = K_{\mu} \Gamma^{\mu}_{\alpha \beta} t^\alpha t^\beta = 0\]
\end{proof}

The real power of the Killing vector method comes from our ability to identify Killing vectors from the coordinate form of the metric. In particular, if the metric does not depend on some coordinate, then there will be a Killing vector corresponding to that coordinate.

\begin{theorem}
Then, the vector $K^{\mu} = \delta_{\kappa}^{\mu}$ for some fixed index $\kappa$ is a Killing vector if and onl if $\partial_{\kappa} g_{\alpha \beta} = 0$, that is $g_{\alpha \beta}$ goes not depend on $x^{\kappa}$.
\end{theorem}

\begin{proof}
With lowered indices, $K_{\mu} = g_{\mu \nu} K^\mu = g_{\mu \nu} \delta_{\kappa}^{\nu} = g_{\mu \kappa}$. Now consider the Killing term,
\begin{align*}
\nabla_{\mu} K_{\nu} + \nabla_{\nu} K_{\mu} & = \partial_{\mu} g_{\nu \kappa} + \partial_{\nu} g_{\mu \kappa} - 2 g_{\alpha \kappa} \Gamma^{\alpha}_{\mu \nu}
\end{align*}
Now we use the explict form of the Christoffel symbols in terms of the metric,
\[ \Gamma^\alpha_{\mu \nu} = \frac{1}{2} g^{\alpha \beta} \left( \partial_{\mu} g_{\nu \beta} + \partial_{\nu} g_{\mu \beta} - \partial_{\beta} g_{\mu \nu} \right) \]
Plugging in,
\begin{align*}
\nabla_{\mu} K_{\nu} + \nabla_{\nu} K_{\mu} & = \partial_{\mu} g_{\nu \kappa} + \partial_{\nu} g_{\mu \kappa} - g_{\alpha \kappa} g^{\alpha \beta} \left( \partial_{\mu} g_{\nu \beta} + \partial_{\nu} g_{\mu \beta} - \partial_{\beta} g_{\mu \nu} \right)
\\
& = \partial_{\mu} g_{\nu \kappa} + \partial_{\nu} g_{\mu \kappa} - \delta^{\beta}_{\kappa} \left( \partial_{\mu} g_{\nu \beta} + \partial_{\nu} g_{\mu \beta} - \partial_{\beta} g_{\mu \nu} \right)
\\
& = \partial_{\mu} g_{\nu \kappa} + \partial_{\nu} g_{\mu \kappa} - \left( \partial_{\mu} g_{\nu \kappa} + \partial_{\nu} g_{\mu \kappa} - \partial_{\kappa} g_{\mu \nu} \right) = \partial_{\kappa} g_{\mu \nu}
\end{align*}
Therefore, the Killing criterion,
\[ \nabla_{\mu} K_{\nu} + \nabla_{\nu} K_{\mu} = 0 \iff \partial_{\kappa} g_{\mu \nu} = 0\]
is satisfied if and only if $\partial_{\kappa} g_{\mu \nu} = 0$.
\end{proof}

\begin{corollary}
If $g_{\alpha \beta}$ does not deppend on the coordinate $\kappa$, that is $\partial_\kappa g_{\alpha \beta} = 0$ then for any geodesic $x^{\mu}(\lambda)$ the quantity,
\[P_\kappa = g_{\kappa \mu} \deriv{x^{\mu}}{\lambda} \]
is converved along the geodesic. This quantity is called the canonical momentum in the direction $\kappa$.  
\end{corollary} 

\begin{proof}
If $\partial_{\kappa} g_{\alpha \beta} = 0$ then by the above theorem, $K^\mu = \delta^{\mu}_{\kappa}$ is a Killing vector. Therefore, by Killing's theorem, the quantity,
\[ P_\kappa = K_{\mu} \deriv{x^{\mu}}{\lambda} = g_{\mu \nu} \delta^{\nu}_{\kappa} \deriv{x^{\mu}}{\lambda} = g_{\kappa \mu} \deriv{x^{\mu}}{\lambda}\]
is converved along the geodesic.
\end{proof}

We will now apply Killing's theorems to the Schwarzschild geometry.

\subsection{Schwarzschild Geodesics}
The Schwarzschild metric,
\[ g_{\mu \nu}
= 
\begin{pmatrix}
c^2 \sfactor & 0 & 0 & 0 \\
0 & - \sfactor^{-1} & 0 & 0 \\
0 & 0 & - r^2 & 0 \\
0 & 0 & 0 & - r^2 \sin^2{\theta}
\end{pmatrix}
\]
is independent of $t$ and $\phi$. Therefore, we immediately get two killing vectrors $\xi^\alpha = (1, 0, 0, 0)$ and $\zeta^\alpha = (0, 0, 0, 1)$. This give the conserved quantities,
\[ h = P_t = g_{\alpha \beta} \xi^\alpha \deriv{x^\beta}{\lambda} = g_{0 0} \deriv{x^0}{\lambda} = c^2 \sfactor \deriv{t}{\lambda} \]
and 
\[ \ell = - P_\theta = - g_{\alpha \beta} \zeta^\alpha \deriv{x^\beta}{\lambda} = - g_{3 3} \deriv{x^3}{\lambda} = r^2 \deriv{\theta}{\lambda} \]

\subsubsection{Time-Like Geodesics}

We will first consider the conserved quantities along the special geodesics parametrized by proper time,
\begin{align*} 
H &= m P_t = m g_{\alpha \beta} \xi^\alpha \deriv{x^\beta}{\tau} = g_{0 0} \deriv{x^0}{\tau} = m c^2 \sfactor \deriv{t}{\tau}
\\
& = \frac{m c^2 \sfactor}{\sqrt{\sfactor - \frac{\dot{r}^2}{c^2} \sfactor^{-1} - r^2 \left( \frac{\dot{\theta}^2}{c^2} + \sin^2{\theta} \frac{\dot{\phi}^2}{c^2} \right) }}
\end{align*}
which turns out be be exactly the energy of the particle and
\begin{align*} 
L & = - mP_\phi = -m g_{\alpha \beta} \zeta^\alpha \deriv{x^\beta}{\tau} = - m g_{3 3} \deriv{x^3}{\tau} = m r^2 \sin^2{\theta} \deriv{\phi}{\tau} 
\\
& = \frac{m (r^2 \sin^2{\theta}) \, \dot{\phi}}{\sqrt{\sfactor - \frac{\dot{r}^2}{c^2} \sfactor^{-1} - r^2 \left( \frac{\dot{\theta}^2}{c^2} + \sin^2{\theta} \frac{\dot{\phi}^2}{c^2} \right) }} 
\end{align*}
where dots represent derivtives with respect to coordinate time. From the proper time interval,
\[ c^2 = c^2 \sfactor \left( \deriv{t}{\tau} \right)^2 - \sfactor^{-1} \left( \deriv{r}{\tau} \right)^2 - r^2 \left( \deriv{\theta}{\tau} \right)^2 - r^2 \sin^2{\theta} \left( \deriv{\phi}{\tau} \right)^2 \] 
calling $\pderiv{r}{\tau} = u^r$ and plugging in our invariants,
\[ c^2 \sfactor = c^2 \left( \frac{H}{mc^2} \right)^2 - (u^r)^2 - r^2 \sfactor (u^\theta)^2 - \frac{L^2}{m^2 r^2 \sin^2{\theta}} \sfactor   \] 
Since the orbits must be planar due to spherical symmetry, we can require that $\theta = \frac{\pi}{2}$ is constant. Thus, $u^\theta = 0$ and $\sin{\theta} = 1$. Therefore, we get the so called radial equation,
\[ \left( \deriv{r}{\tau} \right)^2 + \frac{L^2}{m^2 r^2} \sfactor - \frac{r_s c^2}{r} = c^2 \left[ \left( \frac{H}{mc^2} \right)^2 - 1 \right] \]

Rewriting this equation in terms of physical quantities and using $H = E + mc^2$ where $E$ is the mechanical energy,
\[ \frac{1}{2} \left( \deriv{r}{\tau} \right)^2 + \frac{L^2}{2 m^2 r^2} \left(1 - \frac{2 M G}{c^2 r} \right) - \frac{MG}{r} = \frac{E}{m} + \frac{E^2}{m^2 c^2} \] 
If we compare this to the Newtonain equation for the energy,
\[ \frac{1}{2} \dot{r}^2 + \frac{L^2}{2 m^2 r^2} - \frac{MG}{r} = \frac{E}{m} \]
we see the two are nearly identical except the general relativity equation has derivatives with respect to propert time rather than coordinate time and there is an extra term, 
\[ - \frac{L^2}{2 m^2 r^2} \frac{2 M G}{c^2 r} = - \frac{M G L^2}{m^2 c^2 r^3} \]
So there is an extra $r^{-3}$ potential showing up in GR. We call the combination,
\[ V_{\mathrm{eff}}(r) = \frac{L^2}{2 m^2 r^2} \left(1 - \frac{2 M G}{c^2 r} \right) - \frac{MG}{r} \]
the Schwarzschild effective potential. The extrema of this function correspond to circular orbits. 

\subsubsection{Light-Like Geodesics}

For a light-like geodesic, the proper time is exactly zero so it is not an available parameter. Here, we will take an arbitrary parameter $\lambda$. From the consition for a null-geodesic,
\[ c^2 \sfactor \left( \deriv{t}{\lambda} \right)^2 - \sfactor^{-1} \left( \deriv{r}{\lambda} \right)^2 - r^2 \left( \deriv{\theta}{\lambda} \right)^2 - r^2 \sin^2{\theta} \left( \deriv{\phi}{\lambda} \right)^2 = 0 \]
As before, for simplicity we restrict to planar orbits with $\theta = \frac{\pi}{2}$ is constant. Plugging in the invariants,
\[ \left( \deriv{r}{\lambda} \right)^2 + \frac{\ell^2}{r^2} \sfactor - \frac{h^2}{c^2}  = 0 \]
We want to find a circlular orbit where,
\[ \deriv{r}{\lambda} = \nderiv{2}{r}{\lambda} = 0 \]
This tells us that,
\[ \deriv{}{r} \left[ \frac{\ell^2}{r^2} \sfactor - \frac{h^2}{c^2} \right] = - 2 \frac{\ell^2}{r^3} \sfactor + \frac{\ell^2}{r^2} \frac{r_s}{r^2} = 0 \]
Therefore,
\[ r_s = 2 (r - r_s) \implies r = \tfrac{3}{2} r_s  \]
This is known as the photon sphere, the only place photons can make circular orbits.
 
\subsection{The Action Approach to Geodesics of the Schwarzschild Metric}

\section{Gravitational Waves}
Mention LIGO

\subsection{Linearized Gravity}

As before, we want to consider gravity in the weak field limit meaning when gravity is very weak and therefore the metric is approximatly flat. We can choose coordinates such that $g_{\mu \nu} = \eta_{\mu \nu} + h_{\mu \nu}$ where we thing of $h_{\mu \nu}$ as being a small perturbation away from being flat. 

It turns out that when we drop a

\subsection{Gravitational Wave Solutions}

\section{Experimental Tests of General Relativity}

\section{Dust and Perfect Fluids}

\section{Electromagnetism in General Relativity}

\subsection{Maxwell's Equations in Curved Spacetime}

\subsection{The Reissner-Nordstr{\"o}m Metric of a Charged Black Hole}

\section{Cosmological Models}

\subsection{Early Models}

\subsection{Dark Energy and the Cosmological Constant}

\subsection{The FriedmannLematreRobertsonWalker Metric}

\subsection{The $\Lambda$CDM Model}

\section{Gravitoelectromagnetism}

\section{Kaluza-Klein Theory}

In a 1919 letter to Einstein, Kaluza proposed that a 5-dimensional theory of general relativity could unify gravity and electromagnetism through a purely geometric theory. Although Kaluza-Klein theory makes incorrect predictions about the charges and masses of elementary particles, the framework has become one the foundational pillars of modern physics leading to Yang-Mills theories. 

\subsection{A Five-Dimensional Space-Time}
\begin{remark}
It will be convnient to use the $(-, +, +, +)$ convention for this chapter.
\end{remark}
\noindent
Consider a metric,
\[ \tilde{g}_{\mu \nu} = \begin{pmatrix}
g_{\mu \nu} & g_{\mu 5} \\
g_{\nu 5} & g_{55}
\end{pmatrix}\]
where tildes will indicate 5-dimensional quantities. Adding a whole new space-time dimension provides far too much dyamical freedom. We require the fifth dimension to be compactified, rolled-up in a small circle, explaining the fact that an extra spatial dimension cannot be observed. The 5-dimensional space-time we construct has the topology of a fiber bundle of the circle $S^1$ over a usual four dimensional Minkowski-like manifold $M^4$. This means the space looks locally like $M^4 \times S^1$. Often, we will take the space to gobally have the topology $M^4 \times S^1$ which we refer to a ``trivial'' bundle.
\bigskip\\
In general, the 5th basis vector will not be orthogonal to the basis $\vec{e}_\mu$ so $g_{\mu 5} = \vec{e}_\mu \cdot \vec{e}_5 \neq 0$. We can decompose $\vec{e}_\mu = \vec{e}_{\mu}^{\, \parallel} + \vec{e}_\mu^{\, \perp}$ where $\vec{e}_{\mu}^{\, \perp} \parallel \vec{e}_5$ and $\vec{e}_{\mu}^{\, \perp} \perp \vec{e}_5$. We then write, $\vec{e}_{\mu}^{\, \parallel} = B_\mu \vec{e}_5$ and thus,
\[ \tilde{g}_{\mu \nu} =  (\vec{e}_{\mu}^{\, \perp} + \vec{e}_\mu^{\, \parallel}) \cdot (\vec{e}_{\nu}^{\, \perp} + \vec{e}_\nu^{\, \parallel}) = \vec{e}_{\mu}^{\, \perp} \cdot \vec{e}_{\nu}^{\, \perp} + \vec{e}_\mu^{\, \parallel} \cdot \vec{e}_{\nu}^{\, \parallel} = g_{\mu \nu} + \phi^2 B_\mu B_\nu \]
Where,
\[g = \vec{e}^{\, \perp}_{\mu} \cdot \vec{e}^{\, \perp}_{\nu} \quad \text{and} \quad \phi^2 = \tilde{g}_{55} = \vec{e}_5 \cdot \vec{e}_5 \quad \text{and} \quad B_\mu = \frac{\vec{e}^{\, \parallel}_\mu \cdot \vec{e}_5}{\vec{e}_5 \cdot \vec{e}_5} = \frac{\vec{e}_\mu \cdot \vec{e}_5}{\vec{e}_5 \cdot \vec{e}_5} =  \frac{\tilde{g}_{\mu5}}{\tilde{g}_{55}} \]
Therefore, the entire 5D metric becomes,
\[ \tilde{g}_{\mu \nu} = \begin{pmatrix}
g_{\mu \nu} + \phi^2 B_\mu B_\nu & \phi^2 B_\mu \\
\phi^2 B_\nu & \phi^2
\end{pmatrix}\]
A simple calculation shows that,
\[ \tilde{g}^{\mu \nu} = 
\begin{pmatrix}
g^{\mu \nu} & - B^\mu \\
- B^\nu & \phi^{-2} + B_\alpha B^\alpha
\end{pmatrix}\]
Furthermore,
\[ \tilde{g} = \det{\tilde{g}_{\mu \nu}} = \phi^2 g \] 
where index juggling is performed with the 4D metric $g_{\mu \nu}$. To be able to project physics down into the base 4D space-time, we impose the cylinder condition,
\[ \partial_5 \tilde{g}_{\mu \nu} = 0 \]
so physical quantities should not change while moving along the circular fifth dimension. 

\subsection{Gauge Transformations}

Suppose we make a coordinate transformation by rotating about the local copy of $S^1$ by an amount dependent on 4D space-time position. As we will see, such a transformation is exactly a local gauge transformation which is why Kaluza-Klein is considered a $U(1)$ gauge theory. Explicitly, consider the transformation, $x'^\mu = x^\mu$ and $x'^5 = x^5 - \chi(x^\mu)$. Then, consider the change in components of the metric,
\[ \tilde{g}'_{\mu \nu} = \pderiv{\tilde{x}^\alpha}{\tilde{x}'^\mu} \pderiv{\tilde{x}^\beta}{\tilde{x}'^\nu} \tilde{g}_{\alpha \beta} \]
In particular,
\[ \phi'^2 = \tilde{g}'_{55} = \pderiv{\tilde{x}^\alpha}{\tilde{x}'^5} \pderiv{\tilde{x}^\beta}{\tilde{x}'^5} \tilde{g}_{\alpha \beta} = \tilde{g}_{55} = \phi^2 \]
since the coordinate transformation does not depend on $x^5$. However,
\[ \phi'^2 B'_\mu = \tilde{g}'_{\mu 5} = \pderiv{\tilde{x}^\alpha}{\tilde{x}'^\mu} \pderiv{\tilde{x}^\beta}{\tilde{x}'^5} \tilde{g}_{\alpha \beta} = \tilde{g}_{\mu 5} + \pderiv{x^5}{x'^\mu} \tilde{g}_{55} = \tilde{g}_{\mu 5} + \phi^2 \, \partial_\mu \chi = \phi^2 ( B_\mu + \partial_\mu \chi)\]
Therefore, since $\phi = \phi'$, we see that $B_\mu$ transforms as a gauge field,
\[ B_\mu' = B_\mu + \partial_\mu \chi \] 
Finally, the 4D part of the metric transforms as,
\[ \tilde{g}'_{\mu \nu} = \tilde{g}_{\mu \nu} + \pderiv{\tilde{x}^5}{x'^\mu}  \tilde{g}_{5 \nu} + \pderiv{\tilde{x}^5}{x'^\nu}  \tilde{g}_{\mu 5} + \pderiv{\tilde{x}^5}{x'^\mu} \pderiv{\tilde{x}^5}{x'^\nu}  \tilde{g}_{5 5} = \tilde{g}_{\mu \nu} + \partial_\mu \chi \tilde{g}_{5 \nu} + \tilde{g}_{\mu 5} \partial_\nu \chi + \tilde{g}_{55} \partial_\mu \chi \partial_\nu \chi  \]
Using our introduced fields,
\[ g'_{\mu \nu} + \phi'^2 B'_\mu B'_\nu = g_{\mu \nu} + \phi^2 \bigg[ B_\mu B_\nu + \partial_\mu \chi B_\nu + B_\mu \partial_\nu \chi \bigg] = g_{\mu \nu} + \phi^2 B'_\mu B'_\nu \]
and thus the 4D space-time metric is left invariant under the gauge transformation. 
\[ g'_{\mu \nu} = g_{\mu \nu} \]
Therefore, rotating locally around the $S^1$ components only changes the gauge field $B_\mu$,
\[ \phi \mapsto \phi \quad \quad B_\mu \mapsto B_\mu + \partial_\mu \chi \quad \quad g_{\mu \nu} \mapsto g_{\mu \nu} \]


\subsection{The Five-Dimensional Christoffel Symbols}

Starting directly from the 5D metric, the Christoffel symbols are easily calculated in terms of their 4D counterparts. For the 4D components,
\begin{align*}
\tilde{\Gamma}^{\alpha}_{\mu \nu} & = \frac{1}{2} \tilde{g}^{\alpha \beta} \left( \partial_\mu \tilde{g}_{\beta \nu} + \partial_{\nu} \tilde{g}_{\mu \beta} - \partial_{\beta} \tilde{g}_{\mu \nu} \right)
\\
& = \Gamma^\alpha_{\mu \nu}  + \frac{1}{2} g^{\alpha \beta} \left( \partial_\mu \phi^2 B_\beta B_\nu + \partial_\nu \phi^2 B_\mu B_\beta - \partial_\beta \phi^2 B_\mu B_\nu \right) + \frac{1}{2} \tilde{g}^{\alpha 5} \left( \partial_\mu \tilde{g}_{5 \nu} + \partial_\nu \tilde{g}_{\mu 5} \right) 
\\
& = \Gamma^\alpha_{\mu \nu} + \phi^2 g^{\alpha \beta} \left(W_{\mu \beta} B_\nu + B_\mu W_{\nu \beta} - B_\mu B_\nu \partial_\beta \ln{\phi^2} \right)
\end{align*}
where I have used the cyclindrical condition $\partial_5 g_{\mu \nu} = 0$ and defined the quantity,
\[ W_{\mu \nu} = \partial_\mu B_\nu - \partial_\nu B_\mu \]
Furthermore,
\begin{align*} 
\tilde{\Gamma}^\alpha_{\mu 5} & = \frac{1}{2} \tilde{g}^{\alpha \beta} \left( \partial_\mu \tilde{g}_{\beta 5} - \partial_\beta \tilde{g}_{\mu 5}  \right) = \frac{1}{2} g^{\alpha \beta} \phi^2 \left( \partial_\mu B_\beta - \partial_\beta B_\mu + B_\beta \partial_\mu \ln{\phi^2} - B_\mu \partial_\beta \ln{\phi^2}  \right) + \frac{1}{2} \tilde{g}^{\alpha 5} \partial_{\mu} \tilde{g}_{55}
\\
& = \frac{1}{2} g^{\alpha \beta} \phi^2 \left( W_{\mu \beta} - B_\mu \partial_\beta \ln{\phi^2}  \right) 
\end{align*}
and finally,
\begin{align*}
\tilde{\Gamma}^\alpha_{55} = - \frac{1}{2} \tilde{g}^{\alpha \beta} \partial_{\beta} \tilde{g}_{55} = - \frac{1}{2} g^{\alpha \beta} \partial_{\beta} \phi^2
\end{align*}
where I can restrict to $\beta \neq 5$ by the cylindrical condition.


\subsection{The Einstein-Hilbert Action for Kaluza-Klein Theory}

To study the dynamics of the Kaluza-Klein metric, we need to calculate the Christoffel symbols and then the curvature tensor. This is a straightforward yet exceedingly tedius calculation so I will simply write down the results. We postulate a 5D Einstein-Hilbert action proportional to the simplest curvature invariant, $R$ the Ricci curvature scalar. This is the exact same form as the action for 4D general relativity. Consider the action,
\[ \tilde{S}_{KK} = \int \frac{1}{2 \tilde{\kappa}} \tilde{R} \sqrt{\tilde{g}} \: \dn{5}{x}\]
Therefore, we need to examine the form of the 5-dimensional quantity $\tilde{R}$. The expression for $\tilde{R}$ follows formally from the form of the metric and the Christoffel symbols,
\[ \tilde{R} = R  - \frac{1}{4} \phi^2 W_{\mu \nu} W^{\mu \nu} - \frac{2}{\phi} \partial_\mu \partial^\mu \phi \]
This is our first hint of the so called ``Kaluza Miricle'' since term,
\[ \mathcal{L}_{\text{``EM''}} = - \frac{1}{4} W_{\mu \nu} W^{\mu \nu} \] 
has exactly the form of the electromagnetic Lagrangian. Therefore, the action becomes,
\[ \tilde{S}_{KK} = \int \left[ \frac{1}{2 \tilde{\kappa}} R - \frac{1}{8 \tilde{\kappa}} W_{\mu \nu} W^{\mu \nu} \right] \phi \sqrt{g} \: \dn{5}{x} - \int \partial_\mu \partial^\mu \phi \: \sqrt{g} \: \dn{5}{x} \]
By the cylinder condition, none of these quantities depends on $x^5$ so we can integrate out by $x^5$. Suppose that $C$ is the period of $x^5$ or equivalently the circumference of the compactified dimension. Then the Kaluza-Klein action becomes,
\[ \tilde{S}_{KK} = \int \left[ \frac{C}{2 \tilde{\kappa}} R - \frac{C}{8 \tilde{\kappa}} \phi^2 W_{\mu \nu} W^{\mu \nu} \right] \phi \sqrt{g} \: \dn{4}{x} - C \int \partial_\mu \partial^\mu \phi \: \sqrt{g} \: \dn{4}{x} \]
Now, one last bit of alchemy. Since the constant $\tilde{\kappa}$ is arbitrary, set,
\[ \tilde{\kappa} = \frac{8 \pi G C}{c^4} \] 
Then we define the vector potential $A_\mu = \sqrt{\frac{C}{2 \tilde{\kappa}}} B_\mu$ and the force tensor $F_{\mu \nu} = \partial_\mu A_\nu - \partial_\nu A_\mu$. Then, 
\[ F_{\mu \nu} F^{\mu \nu} = \frac{C}{2 \tilde{\kappa}} \phi^2 W_{\mu \nu} W^{\mu \nu} \]
And at last, the Kaluza Miracle,
\[ \tilde{S}_{KK} = \int \frac{c^4}{16 \pi G} R \: \phi \: \sqrt{g} \: \dn{4}{x} - \int \frac{1}{4} F_{\mu \nu} F^{\mu \nu} \phi^3 \: \sqrt{g} \: \dn{4}{x} - C \int \partial_\mu \partial^\mu \phi \: \sqrt{g} \: \dn{4}{n} = S_{GR} + S_{EM} + S_{SF} \]
the Kaluza-Klien action becomes the action of general relativity plus the action of electromagnetism plus the action of a scalar field. However, there is one sublty, the GR and EM Lagrangians are multiplied by the scalar field $\phi$. However, if $\phi$ is slowly varying then we can approximate it as a constant and absorb it as a constant multiple of the enire Lagrangian. When $\phi \approx \phi_0$ a constant, the action literally reduces to,
\[ \tilde{S}_{KK} = S_{GR} + S_{EM} \]
\subsection{The Field Equations}

We have seen that the Einstein-Hilbert action for the 5D Kaluza-Klein theory gives rise to a 4D Einstein-Hilbert action and the Lagrangian of an electromagnetic-like theory. Varying this action with respect to the fields, we recover the Einstein field equations with an electromagnetic source term from varying the 4D metric, Maxwell's equations from varying the field $A_\mu$ and an equation of motion for the scalar field by varying $\phi$. These results can also be obtained with a slightly different flavor by runing the derivation with the oposite order. Since the Kaluza-Klein action is simple the 5D Einstein Hilbert action,  
\[ \tilde{S}_{KK} = \int \left[ \frac{1}{2 \tilde{\kappa}} \tilde{R} + \tilde{\mathcal{L}}_{M} \right] \sqrt{\tilde{g}} \: \dn{5}{x} \]
varying with respect to the 5D metric $\tilde{g}_{\mu \nu}$ will recover a 5D version of the Einstein field equations with exactly the same form as its 4D general relativity counterpart,
\[ \tilde{R}_{\mu \nu} - \frac{1}{2} \tilde{R} \tilde{g}_{\mu \nu} = \tilde{\kappa} \tilde{T}_{\mu \nu} \]
As before, I will restrict to 5D ``vacuua'' in which $T_{\mu \nu} = 0$. We shall consider the different components of the Einstein field equations. First, the 4D space-time part,
\[ \tilde{R}_{\mu \nu} - \frac{1}{2} \tilde{R} \tilde{g}_{\mu \nu} = 0\]
gives when expanded in term of 4D quantities,
\[ R_{\mu \nu} - \frac{1}{2} R g_{\mu \nu} = \frac{8 \pi G}{c^4} \phi^2 \left(F_{\mu \alpha} {F_{\nu}}^{\alpha} - \frac{1}{4} g_{\mu \nu} F_{\alpha \beta} F^{\alpha \beta} \right) + \frac{1}{\phi} \left( \nabla_\mu \nabla_\nu \phi - g_{\mu \nu} \phi \right) \]
which is the 4D Einstein field equations with an electromagnetic energy-momentum tensor and a strange scalar field energy-momentum. 
Using the fact that,
\[ \tilde{R}_{\mu \nu} - \frac{1}{2} \tilde{R} \tilde{g}_{\mu \nu} = 0 \implies \tilde{R}_{\mu \nu} = 0\] 
by the standard trace trick then we get,

\[ \tilde{R}^{5 \mu} = 0 \implies \frac{1}{2} \nabla_{\nu} \left( \phi^3 F^{\mu \nu} \right) = 0 \]
For a slowly varying $\phi$ field this tells us that,
\[ \nabla_\nu F^{\mu \nu} = 0 \]
which is the Maxwell equations. 
Finally, 
\[ \tilde{R}_{55} = 0 \implies \nabla_\mu \nabla^\mu \phi = \frac{1}{4} \phi^4 F_{\alpha \beta} F^{\alpha \beta} \]
which tells us that the electromagnetic field is the source of this strange new scalar field. 

\subsection{The Lorentz Force Law}

We now want to consider the geodesics in this 5D Kaluza-Klein spacetime. In particular, we care about the 4D projections of these trajectories. Unfortunatly, the full geodesic equation has many many terms. Speficially, we want to look at the terms contracted with $\tilde{\Gamma}^{\mu}_{\alpha \beta}$ and $\tilde{\Gamma}^{\mu}_{\alpha 5}$. We get,
\[ \deriv{\tilde{U}^\mu}{s} + \Gamma^\mu_{\alpha \beta} \tilde{U}^\alpha \tilde{U}^\beta + \sqrt{\frac{8 \pi G}{c^4}} g^{\mu \nu} \phi^2 \left( F_{\alpha \nu} - A_{\alpha} \partial_{\nu} \ln{\phi^2} \right) \tilde{U}^\alpha \tilde{U}^5 + O(A^3) = 0 \]
Furthermore, the cylinder condition tells us that $\partial_5 g_{\alpha \beta} = 0$ therefore, the constant vector $\xi^\mu = (0, 0, 0, 0, 1)$ is a Killing vector so the quantity,
\[ \xi^\mu \tilde{U}_\mu = \tilde{U}_5 \]
is conserved along geodesics. Therefore, we can write,
\[ \deriv{\tilde{U}^\mu}{s} + \Gamma^\mu_{\alpha \beta} \tilde{U}^\alpha \tilde{U}^\beta = \sqrt{\frac{8 \pi G}{c^4}} \: \phi^2 \: \tilde{U}^5 \: {F^\mu}_{\alpha} \tilde{U}^\alpha + O(A^2) \]
This is the Lorentz force law if we set,
\[ \frac{q}{mc} = \sqrt{\frac{8 \pi G}{c^4}} \tilde{U}^5\]
The velocity in the compactified dimension is the charge to mass ratio of the particle!

\subsection{Charge Quantization}

Now we add a tad bit of quantum mechainics! We have particles constrained to a closed periodic circle in the $x^5$ direction. Therefore, a quantum particle cannot have an arbitrary momentum in the $x^5$ direction. If we want to have definite momentum (corresponding to a state with definite charge) then we need to have a standing wave in the $x^5$ direction. Therefore we need to have $C$ be an integer number of wavelengths $n \lambda$. Thus,
\[ \lambda = \frac{h}{p} = \frac{h}{m \tilde{U}^5} = \frac{C}{n} \]  
Therefore, solving for $\tilde{U}^5$ we arrive at a condition on the charge,
\[ q = \frac{n}{C} \frac{h \sqrt{8 \pi G}}{c}  \]
and therefore charge is quantized in units of,
\[ q_Q = \frac{1}{C} \frac{h \sqrt{8 \pi G}}{c} \]

\section{Appendix A. The Calculus of Variations}

\end{document}