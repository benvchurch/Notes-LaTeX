\documentclass[12pt]{article}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=blue,
}

\usepackage{import}
\import{./}{LogicCommands}

\newcommand{\red}{\triangleright}
\newcommand{\aconv}{\equiv_{\alpha}}
\newcommand{\bredo}{\red_{\beta,1}}
\newcommand{\bred}{\red_{\beta}}
\newcommand{\etared}{\red_{\eta}}
\newcommand{\etaredo}{\red_{\eta,1}}
\newcommand{\bered}{\red_{\beta\eta}}
\newcommand{\beredo}{\red_{\beta\eta,1}}

\begin{document}
\author{Benjamin Church}
\title{\Huge $\lambda$-Calculi}

\section{Introduction}


The $\lambda$-calculus (here we first introduce pure untyped $\lambda$-calculus) is a formal system designed to capture of the notions of ``function'' and ``composition''.

\begin{rmk}
A $\lambda$-expression will be a finite string made from the symbols $\lambda$, $.$, and an infinite list of variable symbols $x, y, z, \cdots$ or $a,b,c, \cdots$ or $x_1, x_2, x_3, \dots$ whatever you want to call them. We think of $\lambda x . M$ as the function that takes in $x$ and returns $M$ where $M$ is an expression possibly involving $x$. 
\end{rmk} 

\begin{defn}
A \textit{well-formed} $\lambda$-expression, or $\lambda$-\textit{term}, is defined recursively via,
\begin{enumerate}
\item any variable is a $\lambda$-term
\item if $M$ is a $\lambda$-term then $\lambda x . M$ is a $\lambda$-term
\item if $M$ and $N$ are $\lambda$-terms then $(M N)$ is a $\lambda$-term.
\end{enumerate}
The set of $\lambda$-terms is denoted $\Lambda$.
\end{defn}

\begin{rmk}
We have already said that we should interpret $\lambda x . M$ as a function. Then $(M, N)$ is an ``application'' of the function $M$ to $N$. We think of $((\lambda x . M) N)$ ``evaluating'' to $M[x := N]$ which is how this system captures the essence of functions and computation as evaluation though substitution. Although intutively we think of $\lambda$-terms as functions, that actually take an input and produce a well-defined output, this is actually difficult to define because we will have to decide when a computation is ``finished'' and in fact computations may not halt complicating our desire to call these things functions. A major goal will be to somehow interpret these objects as honest-to-god functions. For now, we take a different perspective not that $\lambda$-terms are ``machines'' but rather they are formal strings in a formal system. To create a formal system we need ``rules of inference'' which are conventionally called conversions and reductions.
\end{rmk}

\begin{defn}
A $\lambda$-term of the form $(\lambda x.M) \, N$ is called a $\beta$-\textit{redex} and its $\beta$-\textit{reduction} is the corresponding term $M [x := N]$. We write,
\[ (\lambda x.M) \, N \bredo M [x := N] \]
If a term $M$ can be converted to $N$ via a finite sequence of $\beta$-reductions we write,
\[ M \bred N \]
Then the equivalence relation generated by this (using zigzags) is called $\beta$-equivalence and writen as $M =_\beta N$. 
\end{defn}

\begin{example}
$( \lambda x . x) y \bredo y$ so we say that $\lambda x . x$ is the identity function.
\end{example}

\begin{defn}
A $\lambda$-term $M$ is a \textit{normal form} if it does not contain any $\beta$-redices. We say that $N$ \textit{is a normal form} of $M$ if $N$ is a normal form and $M \bred N$.
\end{defn} 

\begin{theorem}[Church-Rosser]
Let $M, P, Q$ be $\lambda$-terms such that $M \bred P$ and $M \bred Q$ then there exists a $\lambda$-term $T$ such that $P \bred T$ and $Q \bred T$. We express this with the diagram,
\begin{center}
\begin{tikzcd}[row sep = large]
& M \arrow[rd, "\bred"] \arrow[ld, "\bred"'] 
\\
P \arrow[rd, dashed, "\bred"'] & & Q \arrow[ld, dashed, "\bred"]
\\
& T
\end{tikzcd}
\end{center}
\end{theorem} 

\begin{cor}
Suppose $M, N$ are $\lambda$-terms with $M =_\beta N$ then there exists a $\lambda$-term $T$ such that $M \bred T$ and $N \bred T$. We say that $M$ and $N$ ``compute the same value''.
\end{cor}

\begin{cor}
The normal form of $M$ (if it exists) is unique.
\end{cor}

\begin{example}
A $\lambda$-term need not admit a normal form. For example let,
\[ \omega \equiv \lambda x . (x x) \]
this is the function that applies its input to itself. What happens if we apply $\omega$ to itsef then we get,
\[ \Omega \equiv (\omega \omega) \]
and it is easy to see that,
\[ \Omega \bredo \Omega \]
and there are no other possible $\beta$-reductions. Therefore $\Omega$ does not have a $\beta$-normal form. We can think of it as corresponding to a computation that does not halt.
\end{example}

\section{Arithmetic and Logic in the $\lambda$-Calculus}

Functions have a built-in way of expressing natural numbers, namely counting the number of iterates of a function. Therefore we can define the Church numerals as follows,
\[ \underline{n} \equiv \lambda f . \lambda x . (f^n \; x) \]
where $f^n$ means the expression $(f \; (f \; (f \; \cdots)))$ iterated $n$ times. We think of $n$ as expressing the function which takes in a function $f$ and returns its $n^{\text{th}}$ iterate. We can use this to define sucessor,
\[ \text{succ} \equiv \lambda n . (\lambda f . \lambda x. f \, (n \; f \; x)) \]
and addition,
\[ \text{plus} \equiv \lambda m . \lambda n. \lambda f. \lambda x . m \; f \; (n \; f \; x) \equiv \lambda m . \lambda n . \lambda f . (m \; \text{succ}) \; n\]
which is just composition of the two iterations or equivalently $(m \; \text{succ})$ which is the function that applies the sucessor function $m$ times applied to $n$. However, it is multiplication which shows the true flexibility of the system. We define,
\[ \text{mult} \equiv \lambda m . \lambda n . \lambda f . \lambda x . (m \; (n \; f) \; x) \equiv \lambda m . \lambda n . (m \; (\text{plus} \; n)) \]
which applies $m$ the ``apply its input $m$ times'' function to $(n \; f)$ which is the function $f^n$ so we get $mn$ iterates of $f$. Equivalently we can iterate $(\text{plus} \; n)$ the ``add $n$'' function $m$ times. 
Likewise, boolean values are naturally represented by their corresponding branching behavior, true should take in two functions and return the first while false should take in two functions and do the latter such that applying a boolean executes an if-then statment. Thus,
\[ \text{true} \equiv \lambda p . \lambda q . p \quad \text{and} \quad \text{false} \equiv \lambda p . \lambda q . q \]
I will leave it as an exercise to produce $\lambda$-terms expressing the basic logical operations. 

\begin{defn}
We say that a function $f : \N \to \N$ is \textit{represented} by an untyped $\lambda$-term $F$ if for all $n \in \N$,
\[ (F \; \underline{n}) =_{\beta} [\underline{f(n)}] \]
If there exists such an $F$ we say that $f$ is representable. If $F$ can be chosen such that it has a normal form then we say that $f$ is strongly representable.
\end{defn}

\begin{rmk}
We will see that every computable function is representable but not necessarily strongly representable. 
\end{rmk}

\section{``Consistency'' of the $\lambda$-Calculus (SKIP)}

EARLY FORM INCONSISTENT

Look at section here https://plato.stanford.edu/entries/lambda-calculus/

and in Barendregt's book. 

THIS FORM IS CONSISTENT IN THE SENSE OF CANNOT DERIVE EVERYTHING

CURY'S PARADOX

\section{Recursion and Fixed Points}

We've discussed how $\lambda$-terms can represent integer functions. However, so far we've only implemented very simple function such as addition and multiplication. It is not at all clear how to implement complex behavior without loops. In fact, we want to be able to implement general recursion but this seems impossible without self-referential definitions which are not allowed in the construction of our formal language. 
\bigskip\\
Although there does not appear to be a way to \textit{construct} recursive functions we do have a way to check if a given $\lambda$-term represents the required recursive function using a fixed-point expression. Indeed, suppose that we want to find a function $f$ which satisfies the recursive definiton,
\[ f(x) = 
\begin{cases}
g(f(x-1), x) & x > 0
\\
n & x = 0
\end{cases}\]
Suppose moreover that $g$ is represented by a $\lambda$-term $G$. Then consider the $\lambda$-term,
\[ T :\equiv \lambda f . \lambda x . (\text{IsZero} \; x) \; \underline{n} \; (G \; (f \; (\text{pred} \; x)) \; x)) \]
which takes a function $f$ and returns the function expressed by the RHS of the recursive definition. Therefore, we are searching for a $\lambda$-term $F$ such that,
\[ (T \; F) =_\beta F \]
This will then represent the function $f$. Therefore, we have reduced the problem to constructing fixed-points of $T$ up to $\equiv_{\beta\eta}$.  
\bigskip\\
Consider the following $\lambda$-term,
\[ Y :\equiv \lambda f. (\lambda x. f \, (x x)) \; (\lambda x. f \, (x x)) \]
called Haskell Curry's paradoxical combinator. Since that is quite a mouthful and its usual name has been coopted, I will simply call it ``Y''. 
Notice that, like $\Omega$, we have,
\[ (Y \; f) \bredo (f \; (Y \; f)) \]
In particular, $(Y \; T)$ is a fixed point of $T$. Therefore, astonishingly, in untyped $\lambda$-calculus, every $\lambda$-term admits a fixed point. Hence the recursion problems allways admit solutions. 

PHILOSOPHICAL MUSINGS ON THE NATURE OF THESE FIXED POINT PROBLEMS


ANOTHER WAY TO GET FIXED POINTS, ARE THESE THE SAME??

To even make sense of this question, we first need a notion of convergence of functions suitable for these integer functions. Moreover, because we want to ask if the limit of the representing $\lambda$-terms agree, we need some sort of \textit{model} in which the $\lambda$-terms are \textit{all} representing functions which we can reason about topologically. This is the subject we now turn to. 

\section{$\lambda$-Models (DO AT THE END)}

From the begining, the question arrose: if $\lambda$-terms are supposed to be ``anonomous functions'' what space are they functions on? More precisely, we want a notion of a space such that it's automorphisms are exactly the equivalence classes of $\lambda$-terms. This space must have some curious properties. Since $\lambda$-terms can be applied to any other $\lambda$-term it must be the case that each point of the space represents a function on it and every ``nice'' function arises in this fasion. For example, this couldn't be done in the category of sets since it would be saying there is a set $X$ with $2^X = X$ which is impossible by Cantor's theorem. We need a more interesting notion to capture what's going on in the untyped $\lambda$-calculus. 

\newcommand{\Var}{\mathrm{Var}}

\begin{defn}
A $\lambda$-\textit{interpretation} is a set $D$ and a \textit{valuation} function $\rho : \Var \to D$
\end{defn}

\begin{defn}
A $\lambda$-\textit{model} is a triple $(D, \bullet, \dbrac{-})$ with $\bullet$ a binary operation on $D$ and $\dbrac{-}$ a function giving for each valuation $\rho$ a mapping $\dbrac{-}_\rho : \Lambda \to D$ which satisfies,
\begin{enumerate}
\item if $x$ is a variable $\dbrac{x}_\rho = \rho(x)$
\item for any $\lambda$-terms $M, N$ then $\dbrac{M \, N}_\rho = \dbrac{M}_{\rho} \bullet \dbrac{N}_\rho$
\item for all variables $x$, terms $M$, and elements $d \in D$ we have $\dbrac{\lambda x . M}_\rho \bullet d = \dbrac{M}_{\rho [x := d]}$
\item for all terms $M$ and valuations $\rho, \sigma$ we have $\dbrac{M}_\rho = \dbrac{M}_\sigma$ if $\rho(x) = \sigma(x)$ for all free varaibles $x$ of $M$
\item for all terms $M$ and variables $x,y$ then $\dbrac{\lambda x . M}_\rho = \dbrac{\lambda y . M [x := x]}_{\rho}$ if $y$ is not free in $M$
\item for all terms $M, N$ if for all $d \in D$ we have $\dbrac{M}_{\rho [x := d]} = \dbrac{N}_{\rho [x := d]}$ then $\dbrac{\lambda x . M}_\rho = \dbrac{\lambda x . N}_\rho$.
\end{enumerate}
\end{defn}

\begin{rmk}
The \textit{term model} or \textit{trivial model} is given by $\Lambda$ modulo $\beta$-equivalence and composition given by application. This is a model but it is unenlightening. Dana Scott searched for a more interesting model. 
\end{rmk}

\subsection{Syntax-Free Models}

DO THIS

\section{Domain Theory}

\begin{rmk}
We use ``monotone'' and ``order-preserving'' synonymously to mean $x \le y \implies f(x) \le f(y)$.
\end{rmk}


\begin{defn}
A \textit{directed-complete partial order} (dcpo) is a poset $(P, \le)$ such that every directed subset has a supremum. 
\end{defn}

\begin{rmk}
A directed subset $D \subset P$ is a subset such that every finite subset of $D$ has an upper bound in $D$. Equivalently for each $a, b \in D$ there is $c \in D$ with $a,b \le c$. 
\end{rmk}

\begin{rmk}
A somewhat technical axiom of choice argument shows that it suffices to check that every chain has a supremum in order for a poset to be a dcpo. 
\end{rmk}

\begin{rmk}
It is good to contrast a dcpo with the related notion of the complete lattice, a poset such that every subset has a supremum. Taking the supremum over the set of lower bounds gives all infima as well. Then a complete lattice is a lattice because the supremum and infimum of $\{ a, b \}$ give the meets and joins. However, $\{ a, b \}$ is \textit{not} directed and therefore we should not expect a dcpo to be either a meet or a join semilattice.  
\end{rmk}

\begin{defn}
A \textit{pointed dcpo} or \textit{cpo} is a dcpo $(P, \le)$ with a least element $\bot \in P$.
\end{defn}

\begin{rmk}
Remember what we are after, spaces that are naturally $\lambda$-modules. Also we are expecting that, using $Y$, any function arising from a $\lambda$-term has a fixed point and therefore we are looking for spaces whose nice functions all have fixed points. The following proposition shows that we are on the right track. 
\end{rmk}

\begin{prop}
Let $P$ be a pointed poset. Then the following are equivalent,
\begin{enumerate}
\item $P$ is a cpo
\item every monotone map $f : P \to P$ has a last fixpoint.  
\end{enumerate}
\end{prop}

\subsection{Continuity}

\begin{defn}
Let $f : P \to Q$ be a monotone map of dcpos. We say that $f$ is,
\begin{enumerate}
\item \textit{Scott-continuous} if for every directed subset $D \subset P$ we have $f(\sup D) = \sup f(D)$
\item \textit{strict} if $P$ and $Q$ are pointed and $f(\bot) = \bot$.
\end{enumerate}
We denote the poset (pointwise) of continuous functions by $[P \to Q]$ and the subposet of strict continuous functions by $[P \to Q]_{\bot}$.
\end{defn}

\begin{prop}
If $P$ and $Q$ are (pointed) dcpos then $[P \to Q]$ ($[P \to Q]_{\bot}$) is a (pointed) dcpos where suprema are computed pointwise. 
\end{prop}

\begin{proof}
Let $D \subset [P \to Q]$ be directed. By definition $A_x = \{ f(x) \mid f \in D \}$ is directed so the function,
\[ g(x) = \sup A_x = \sup_{f \in D} f(x) \]
is well-defined. Then for any directed $A \subset P$ notice that,
\[ g(\sup A) = \sup_{f \in D} f(\sup A) = \sup_{f \in D} \sup_{x \in A} f(x) = \sup_{x \in A} \sup_{f \in D} f(x) = \sup_{x \in A} g(x) \]
proving that $g$ is continuous. It is clear that $g$ is the supremum of $D$. 
\end{proof}

\subsection{The Scott Topology}

\begin{defn}
Let $P$ be a dcpos a subset $C \subset P$ is \textit{(Scott) closed} if it is downward and closed under suprema of directed subsets. The \textit{Scott topology} has these as closed sets.  
\end{defn}

\begin{prop}
A map $f : P \to Q$ of dcpos is Scott-continuous if and only if it is continuous in the Scott topology.  
\end{prop}

\begin{proof}
Assume $f$ is Scott-continuous and $C \subset Q$ is closed. Then $f^{-1}(C)$ is downward because $f$ is monotone and if $D \subset f^{-1}(C)$ is directed then $f(\sup D) = \sup f(D) \in C$ so $\sup D \in f^{-1}(C)$. 
\bigskip\\
Conversely, if $f$ is continuous for the Scott topology. For any $x \in P$ the set $D_x = \{ y \in P \mid y \le x \}$ is closed and if $x' \le x$ then $x \in f^{-1}(D_{f(x)}$ so $x' \in f^{-1}(D_{f(x)})$ since it is closed thus $f(x') \in D_{f(x)}$ so $f(x') \le f(x)$ so $f$ is monotone. Furthermore, let $D \subset P$ be directed. Then $f^{-1}(D_{\sup f(D)})$ is closed and $D \subset f^{-1}(D_{\sup f(D)})$ so $\sup D \in f^{-1}(D_{\sup f(D)})$ so $f(\sup D) \le \sup f(D)$ but also $f(D) \le f(\sup D)$ so $f(\sup D) = \sup f(D)$.  
\end{proof}

\subsection{Fixed Points}

\renewcommand{\fix}{\mathsf{fix}}
\renewcommand{\it}{\mathsf{it}}

When you first learn about functions and fixpoints you might notice that sometimes to find a fixpoint you can just iterate $f$. Take an arbitrary $x_0$ and then consider the sequence $f(x_0), f^2(x_0),  f^3(x_0), \dots$. If this converges it is guaranteed to be a fixpoint. For example, when I was bored in highschool, I took a random number on my calculator and hit $\cos$ over and over. It allways approaches $0.739085 \cdots$ the cosine fixpoint. It turns out, for continuous $f$, this process always converges in a cpo. 

\begin{theorem}[Kleene]
Let $D$ be a cpo,
\begin{enumerate}
\item every continuous $f : D \to D$ has a least fixpoint,
\[ \fix(f) = \sup_{n \in \N} f^n(\bot) \]
\item the map $\fix : [D \to D] \to D$ is continuous. 
\end{enumerate}
\end{theorem}

\begin{proof}
The set $\{ f^n(\bot) \}_{n \in \N}$ is a chain by monotonicity. Thus by completeness,
\[ f(\sup_{n \in \N} f^n(\bot)) = \sup_{n \in \N} f(f(n)) = \sup_{n \in \N} f^{n+1}(\bot) = \sup_{n \in \N} f^n(\bot) \]
so $\fix(f)$ is a fixpoint of $f$. Let $x \in D$ be any other fixpoint. By monotonicity $f^n(\bot) \le f^n(x) = x$ and thus $\sup_{n \in \N} f^n(\bot) \le x$.
\bigskip\\
(DONT DO THE SECOND PART)
Now we address the continuity of $\fix$. Notice that $\fix = \sup_{n \in \N} \it_n$ where $\it_n : f \mapsto f^n(\bot)$. Since $[[D \to D] \to D]$ is a dcpo it suffices to show that $\it_n$ is continuous. We proceed by induction. $\it_0$ is constant so this is continuous. Then for $F \subset [D \to D]$ directed, consider,
\begin{align*}
\it_{n+1}(\sup F) & = (\sup F)(\it_n(\sup F)) = (\sup F)(\sup_{f \in F} \it_n(f)) 
\\
& = \sup_{g \in F} g (\sup_{f \in F}(\it_n(f))) = \sup_{g \in F} \sup_{F \in F} g(\it_n(f)) = \sup_{f \in F} \sup_{g \in F} g(\it_n(f))
\\
& = \sup_{f \in F} f(\it_n(f)) 
\end{align*}
because the map $(f, g) \mapsto g(\it_n(f))$ is monotone. 
\end{proof}

\subsection{Scott Domains}

\subsection{Scott's Model $D_{\infty}$}

To build a $\lambda$-model, we start with the trivial cpo $\N^+$ which is $\N$ with the trivial order adjoin $\bot$. We think of these elements as the Church numerals along with a symbol for ``ill-defined'' or ``DNE''. Then we get an interpretation of $\lambda$-terms as follows. If $M =_\beta \underline{n}$ then we send $M \mapsto n$ and otherwise $M \mapsto \bot$. This is well-defined because Church numerals are normal so no two can be $\beta$-equivalence by the Church-Roser theorem. However, this alone is not a $\lambda$-model, there is no composition law! What we need to do, is glue in the continuous functions $[\N^+ \to \N^+]$ so we can apply them to our elements $\N^+$. We then interpret a $\lambda$-term as $M \mapsto f$ for $f \in [\N^+ \to \N^+]$ such that for each $n \in \N$ we have $(M \; \underline{n}) =_\beta \underline{f(n)}$ and $f(n) = \bot$ if $(M \; \underline{n})$ does not reduce to a Church numeral. Finally, I need to say what $f(\bot)$ is. To impose continuity $f(\bot) = \bot$ unless $f|_{\N}$ is constant and then $f(\bot) = f(\N)$. Howver, we have not completed a $\lambda$-model because we don't know how to apply integer functions to eachother or how to actually do this ``gluing''. The ``building-up'' process of cpos is accomplished by the following construction,

\begin{defn}
Let $D, D'$ be cpos. A \textit{projection} from $D' \to D$ is a pair $(\phi, \psi)$ of continuous maps $\phi : D \to D'$ and $\psi : D' \to D$ such that,
\[ \psi \circ \phi = \id_D \quad \text{and} \quad \phi \circ \psi \le \id_{D'} \]
\end{defn}


Now we construct a sequence of cpos inductively. Let $D_0 = \N^+$ (adjoin $\bot$ to $\N$ equipped with the trivial order) then define $D_{n+1} = [D_n \to D_n]$. We construct projections $D_{n+1} \to D_n$ inductively as follows. Let $\phi_0(d) = \kappa_d$ where $\kappa$ is the constant function and $\psi_0(c) = c(\top)$. Then we define $\phi_n : D_n \to D_{n+1}$ and $\psi_n : D_{n+1} \to D_n$,
\[ \phi_n(\sigma) = \phi_{n-1} \circ \sigma \circ \psi_{n-1} \quad \text{ and } \quad \psi_n(\tau) = \psi_{n-1} \circ \tau \circ \phi_{n-1} \]
It is not difficult to show that this gives a sequence of projections. Then we define Scott's model,
\[ D_{\infty} = \varinjlim_{n} D_n \]
Explicitly the elements are sequences $(d_0, d_1, d_2, \dots)$ such that $\psi_n(d_{n+1}) = d_{n}$ for all $n$ with the ordering pointwise. 

\begin{prop}
$D_\infty$ is a cpo with $\bot = (\bot_0, \bot_1, \bot_2, \dots)$ and if $A \subset D_{\infty}$ is directed then,
\[ \sup X = (\sup X_0, \sup X_1, \sup X_2, \dots) \]
and there are projections $D_{\infty} \to D_n$ with $\phi_n : d \mapsto d_n$ and corresponding inclusion $\psi_n : d \mapsto (\psi_{n,0}(d), \psi_{n,1}(d), \psi_{n,2}(d), \dots)$.
\end{prop}

We can then define the composition on $D_{\infty}$ as,
\[ a \bullet b = \sup_n \psi_n(a_{n+1}(b_n)) \]

\begin{prop}
The composition gives an isomorphism $D_{\infty} \iso [D_{\infty} \to D_{\infty}]$. 
\end{prop}

Then we can show there is a natural way to make $(D_\infty, \bullet)$ into a $\lambda$-model extending the interpretation we gave for the first two stages. How are we supposed to think about elements of $D_\infty$. The relation $\le$ is expressing the idea of ``defined on a larger set''. Indeed, for $f,g \in D_1$ we have $f \le g$ iff $f(n) = g(n)$ if $f(n) \neq \bot$ and whenever $g(n) = \bot$ then $f(n) = \bot$ meaning $g$ is defined at least everywhere $f$ is and on the domain where $f$ is defined the two functions agree. Then the global bottom element $\bot \in D_\infty$ represents the function defined nowhere. Thefore, our supremum processes can be thought of as producing the limit of a sequence of functions that are getting progressively defined more often. 

\subsection{$D_\infty$ is a $\lambda$-model}

THINK OF THIS AS COMPUTABLE APPROXIMATION

\subsection{Fixpoints in $D_{\infty}$}

Using our interpretation of $D_{\infty}$ recall that the fixpoint operator takes the form,
\[ \fix(f) = \sup_{n \in \N} f^n(\bot) \]
Consider the recursion operator $T$ we defined before. Remember that $\fix(T)$ is a solution to the self-referential recursive definition. Explicitly, we get a sequence of functions,
\[ \bot, T(\bot), T^2(\bot), T^3(\bot), \dots \]
What do these mean? The first is just defined nowhere. The second is the function (when applied to Church numerals),
\[ T(\bot)(x) = \begin{cases}
n & x = 0
\\
\bot & x > 0
\end{cases} \]
so it is defined just at $x = 0$ to equal the base case. Then,
\[  T^2(\bot)(x) = 
\begin{cases}
n & x = 0
\\
G(n, 1) & x = 1
\\
\bot & x > 1
\end{cases}
\]
and so on. We see that this is converging to the expected behavior of the recursive function. 
\bigskip\\
However, recall that we have a different mysterious way of producing fixed points, the operator $Y$. In Scott's model $Y = \fix$ but this does not always happen.

\begin{rmk}
Using the $D_{\infty} \to [D_{\infty} \to D_{\infty}]$ is an isomorphism we can regard $\fix \in D_{\infty}$. 
\end{rmk}

\begin{prop}
In $D_{\infty}$ we have $Y = \fix$.
\end{prop}

\begin{proof}
It is clear that $\fix \le Y$ since $\fix$ gives the smallest fixpoint. Conversely, for $x \in D$ we have,
\[ Y \bullet x = X \bullet X \]
where $X$ is such that $X \bullet d = x \bullet (y \bullet y)$. Then by definition,
\[ X \bullet X = \sup_{n \in \N} \psi_n(X_{n+1}(X_n)) \]
\end{proof}

\section{The Simply-Typed $\lambda$-Calculus}

\subsection{Expressible Functions}

\subsection{Models}

\subsection{Curry-Howard}

\section{References}

\begin{enumerate}
\item https://www.youtube.com/watch?v=7cPtCpyBPNI

\item http://www.cs.nott.ac.uk/~pszgmh/dom4.pdf

\item  https://en.wikipedia.org/wiki/Kleene_fixed-point_theorem
\end{enumerate}

\end{document}
